<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="yanyq">
  <meta name="keywords" content="">
  <title>深度学习入门 - 朝与暮</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/github-gist.min.css" />


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_fmb4a04yx8h.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_ijqayz9ro8k.css">




<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


<meta name="generator" content="Hexo 4.2.1"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Fluid</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">
              <i class="iconfont icon-home-fill"></i>
              首页</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">
              <i class="iconfont icon-archive-fill"></i>
              归档</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">
              <i class="iconfont icon-category-fill"></i>
              分类</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">
              <i class="iconfont icon-tags-fill"></i>
              标签</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">
              <i class="iconfont icon-user-fill"></i>
              关于</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
                <div class="mt-3 post-meta">
                  <i class="iconfont icon-date-fill" aria-hidden="true"></i>
                  <time datetime="2020-06-09 11:44">
                    2020年6月9日 中午
                  </time>
                </div>
              

              <div class="mt-1">
                
                  
                  <span class="post-meta mr-2">
                    <i class="iconfont icon-chart"></i>
                    7.2k 字
                  </span>
                

                
                  
                  <span class="post-meta mr-2">
                      <i class="iconfont icon-clock-fill"></i>
                    
                    
                    80
                     分钟
                  </span>
                

                
              </div>
            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
            <article class="markdown-body">
              <h1 id="深度学习入门"><a href="#深度学习入门" class="headerlink" title="深度学习入门"></a>深度学习入门</h1><p>颜远青 2020年06月09日</p>
<h2 id="一、深度学习基础"><a href="#一、深度学习基础" class="headerlink" title="一、深度学习基础"></a>一、深度学习基础</h2><h3 id="1-1-深度学习与机器学习的差异"><a href="#1-1-深度学习与机器学习的差异" class="headerlink" title="1.1 深度学习与机器学习的差异"></a>1.1 深度学习与机器学习的差异</h3><p><strong>机器学习</strong>：利用计算机、概率论、统计学等知识，输入数据，让计算机学会新知识。机器学习的过程，就是训练数据去优化目标函数。</p>
<p><strong>深度学习</strong>：是一种特殊的机器学习，具有强大的能力和灵活性。它通过学习将世界表示为嵌套的层次结构，每个表示都与更简单的特征相关，而抽象的表示则用于计算更抽象的表示。</p>
<p>传统的机器学习需要<strong>定义一些手工特征</strong>，从而<strong>有目的的去提取目标信息</strong>， 非常依赖任务的特异性以及设计特征的专家经验。而深度学习可以<strong>从大数据中先学习简单的特征，并从其逐渐学习到更为复杂抽象的深层特征，不依赖人工的特征工程</strong>，这也是深度学习在大数据时代受欢迎的一大原因。</p>
<h3 id="1-2-感知机与多层感知机"><a href="#1-2-感知机与多层感知机" class="headerlink" title="1.2 感知机与多层感知机"></a>1.2 感知机与多层感知机</h3><p>神经网络类型众多，其中最为重要的是多层感知机。为了详细地描述神经网络，我们先从最简单的神经网络说起。</p>
<p><strong>感知机</strong></p>
<p>多层感知机中的特征神经元模型称为感知机，由<em>Frank Rosenblatt</em>于1957年发明。</p>
<p>简单的感知机如下图所示：</p>
<p><img src="/imgs/deeplearning/ch3/3-1.png" srcset="/img/loading.gif" alt=""></p>
<p>其中$x_1$，$x_2$，$x_3$为感知机的输入，其输出为：</p>
<script type="math/tex; mode=display">
output = \left\{
\begin{aligned}
0, \quad if \ \ \sum_i w_i x_i \leqslant threshold \\
1, \quad if \ \ \sum_i w_i x_i > threshold
\end{aligned}
\right.</script><p>假如把感知机想象成一个加权投票机制，比如 3 位评委给一个歌手打分，打分分别为$ 4 $分、$1$ 分、$-3 $分，这$ 3$ 位评分的权重分别是 $1、3、2$，则该歌手最终得分为 $4 \times 1 + 1 \times 3 + (-3) \times 2 = 1$ 。按照比赛规则，选取的 $threshold$ 为 $3$，说明只有歌手的综合评分大于$ 3$ 时，才可顺利晋级。对照感知机，该选手被淘汰，因为：</p>
<script type="math/tex; mode=display">
\sum_i w_i x_i < threshold=3, output = 0</script><p>用 $-b$  代替 $threshold$，输出变为：</p>
<script type="math/tex; mode=display">
output = \left\{
\begin{aligned}
0, \quad if \ \ \boldsymbol{w} \cdot \boldsymbol{x} + b \leqslant 0 \\
1, \quad if \ \ \boldsymbol{w} \cdot \boldsymbol{x} + b > 0
\end{aligned}
\right.</script><p>设置合适的  $\boldsymbol{x}$  和  $b$ ，一个简单的感知机单元的与非门表示如下：</p>
<p><img src="/imgs/deeplearning/ch3/3-2.png" srcset="/img/loading.gif" alt=""></p>
<p>当输入为 $0$，$1$ 时，感知机输出为 $ 0 \times (-2) + 1 \times (-2) + 3 = 1$。</p>
<p>复杂一些的感知机由简单的感知机单元组合而成：</p>
<p><img src="/imgs/deeplearning/ch3/3-3.png" srcset="/img/loading.gif" alt=""></p>
<p><strong>多层感知机</strong></p>
<p>多层感知机由感知机推广而来，最主要的特点是有多个神经元层，因此也叫深度神经网络。相比于单独的感知机，多层感知机的第 $ i $ 层的每个神经元和第 $ i-1 $ 层的每个神经元都有连接。</p>
<p><img src="/imgs/deeplearning/ch3/3.1.1.5.png" srcset="/img/loading.gif" alt=""></p>
<p>输出层可以不止有$ 1$ 个神经元。隐藏层可以只有$ 1$ 层，也可以有多层。输出层为多个神经元的神经网络例如下图所示：</p>
<p><img src="/imgs/deeplearning/ch3/3.1.1.6.png" srcset="/img/loading.gif" alt=""></p>
<h3 id="1-3-前向传播与反向传播"><a href="#1-3-前向传播与反向传播" class="headerlink" title="1.3 前向传播与反向传播"></a>1.3 前向传播与反向传播</h3><p>神经网络的计算主要有两种：前向传播（foward propagation, FP）作用于每一层的输入，通过逐层计算得到输出结果；反向传播（backward propagation, BP）作用于网络的输出，通过计算梯度由深到浅更新网络参数。</p>
<p><strong>前向传播</strong></p>
<p><img src="/imgs/deeplearning/ch3/3.2.1.1.png" srcset="/img/loading.gif" alt=""></p>
<p>假设上一层结点 $ i,j,k,… $ 等一些结点与本层的结点 $ w $ 有连接，那么结点 $ w $ 的值怎么算呢？就是通过上一层的 $ i,j,k,… $ 等结点以及对应的连接权值进行加权和运算，最终结果再加上一个偏置项（图中为了简单省略了），最后在通过一个非线性函数（即激活函数），如 $ReLu$，$sigmoid$ 等函数，最后得到的结果就是本层结点 $ w $ 的输出。 </p>
<p>最终不断的通过这种方法一层层的运算，得到输出层结果。</p>
<p><strong>反向传播</strong></p>
<p><img src="/imgs/deeplearning/ch3/3.2.1.2.png" srcset="/img/loading.gif" alt=""></p>
<p>由于我们前向传播最终得到的结果，以分类为例，最终总是有误差的，那么怎么减少误差呢，当前应用广泛的一个算法就是梯度下降算法，但是求梯度就要求偏导数，下面以图中字母为例讲解一下：</p>
<p>设最终误差为 $ E $且输出层的激活函数为线性激活函数，对于输出那么 $ E $ 对于输出节点 $ y_l $ 的偏导数是 $ y_l - t_l $，其中 $ t_l $ 是真实值，$ \frac{\partial y_l}{\partial z_l} $ 是指上面提到的激活函数，$ z_l $ 是上面提到的加权和，那么这一层的 $ E $ 对于 $ z_l $ 的偏导数为 $ \frac{\partial E}{\partial z_l} = \frac{\partial E}{\partial y_l} \frac{\partial y_l}{\partial z_l} $。同理，下一层也是这么计算，只不过 $ \frac{\partial E}{\partial y_k} $ 计算方法变了，一直反向传播到输入层，最后有 $ \frac{\partial E}{\partial x_i} = \frac{\partial E}{\partial y_j} \frac{\partial y_j}{\partial z_j} $，且 $ \frac{\partial z_j}{\partial x_i} = w_i j $。然后调整这些过程中的权值，再不断进行前向传播和反向传播的过程，最终得到一个比较好的结果。</p>
<h3 id="1-4-标量、向量、矩阵、张量"><a href="#1-4-标量、向量、矩阵、张量" class="headerlink" title="1.4 标量、向量、矩阵、张量"></a>1.4 标量、向量、矩阵、张量</h3><p><strong>标量（scalar）</strong><br>一个标量表示一个单独的数，它不同于线性代数中研究的其他大部分对象（通常是多个数的数组）。我们用斜体表示标量。标量通常被赋予小写的变量名称。 </p>
<p><strong>向量（vector）</strong><br>一个向量表示一组有序排列的数。通过次序中的索引，我们可以确定每个单独的数。通常我们赋予向量粗体的小写变量名称，比如xx。向量中的元素可以通过带脚标的斜体表示。向量$X$的第一个元素是$X_1$，第二个元素是$X_2$，以此类推。我们也会注明存储在向量中的元素的类型（实数、虚数等）。</p>
<p><strong>矩阵（matrix）</strong><br>矩阵是具有相同特征和纬度的对象的集合，表现为一张二维数据表。其意义是一个对象表示为矩阵中的一行，一个特征表示为矩阵中的一列，每个特征都有数值型的取值。通常会赋予矩阵粗体的大写变量名称，比如$A$。</p>
<p><strong>张量（tensor）</strong><br>在某些情况下，我们会讨论坐标超过两维的数组。一般地，一个数组中的元素分布在若干维坐标的规则网格中，我们将其称之为张量。使用 $A$ 来表示张量“A”。张量$A$中坐标为$(i,j,k)$的元素记作$A_{(i,j,k)}$。 </p>
<h3 id="1-5-训练集、验证集与测试集"><a href="#1-5-训练集、验证集与测试集" class="headerlink" title="1.5 训练集、验证集与测试集"></a>1.5 训练集、验证集与测试集</h3><p><strong>训练集</strong>:指的是用于训练的样本集合,主要用来训练神经网络中的参数.</p>
<p><strong>验证集</strong>:用于验证模型性能的样本集合.不同神经网络在训练集上训练结束后,通过验证集来比较判断各个模型的性能.这里的不同模型主要是指对应不同超参数的神经网络,也可以指完全不同结构的神经网络.</p>
<p><strong>测试集</strong>:对于训练完成的神经网络,测试集用于客观的评价神经网络的性能.</p>
<p><strong>训练集、验证集和测试集的划分</strong></p>
<ul>
<li>对于小规模样本集,常用的非配比例是trianing /validation/test 6:2:2.例如共有10000个样本,则训练集分为6000个样本,验证集为2000样本,测试集为2000样本.</li>
<li>对于大规模样本集,则validation/test的比例会减小很多,因为验证(比较)模型性能和测试模型性能一定的样本规模就足够了.例如共有1000000个样本,则训练集分为9980000个样本,验证集分为10000个样本,测试集分为10000个样本.</li>
</ul>
<h3 id="1-6-训练误差与测试误差-泛化误差"><a href="#1-6-训练误差与测试误差-泛化误差" class="headerlink" title="1.6 训练误差与测试误差(泛化误差)"></a>1.6 训练误差与测试误差(泛化误差)</h3><p><strong>训练误差</strong>:模型在训练集上的误差平均值，度量了模型对训练集拟合的情况。训练误差大说明对训练集特性学习得不够，训练误差太小说明过度学习了训练集特性，容易发生过拟合。</p>
<p><strong>测试误差</strong>:模型在测试集上的误差平均值，度量了模型的泛化能力。在实践中，希望测试误差越小越好。</p>
<h3 id="1-7-欠拟合与过拟合"><a href="#1-7-欠拟合与过拟合" class="headerlink" title="1.7 欠拟合与过拟合"></a>1.7 欠拟合与过拟合</h3><p><strong>欠拟合</strong>就是说模型尚未学习完整训练集实例的普适特性。从误差角度来说，欠拟合时训练误差大，测试误差也大。</p>
<p><strong>过拟合</strong>就是模型过度学习了训练集所有特性，导致模型认为训练集中的某些特性也是潜在测试实例具有的一般性质。从误差角度来说，过拟合时训练误差小但测试误差却很大。</p>
<h3 id="1-8-损失函数-目标函数-与评价函数"><a href="#1-8-损失函数-目标函数-与评价函数" class="headerlink" title="1.8 损失函数(目标函数)与评价函数"></a>1.8 损失函数(目标函数)与评价函数</h3><p><strong>损失函数(loss)</strong>:通过最小化损失函数，使模型达到收敛状态，减少模型预测值的误差。</p>
<p><strong>评价函数(metric)</strong>:与损失函数类似，用于评价训练完的模型准确度，不参与模型训练。</p>
<div class="note note-info">
            <p>需要说明的是，相同的任务，采用不同的模型训练时可能采用不同的损失函数，不同的损失函数的数值用来评价不同模型的优劣没有意义，为此，在比较不同模型的优劣时，应该采用一致的评判标准，即采用相同的metric。</p>
          </div>
<h3 id="1-9-学习率"><a href="#1-9-学习率" class="headerlink" title="1.9 学习率"></a>1.9 学习率</h3><p> 在机器学习中，监督式学习通过定义一个模型，并根据训练集上的数据估计最优参数。梯度下降法是一个广泛被用来最小化模型误差的参数优化算法。梯度下降法通过多次迭代，并在每一步中最小化成本函数（cost 来估计模型的参数。学习率 (learning rate)，在迭代过程中会控制模型的学习进度。</p>
<p>在梯度下降法中，都是给定的统一的学习率，整个优化过程中都以确定的步长进行更新， 在迭代优化的前期中，学习率较大，则前进的步长就会较长，这时便能以较快的速度进行梯度下降，而在迭代优化的后期，逐步减小学习率的值，减小步长，这样将有助于算法的收敛，更容易接近最优解。故而如何对学习率的更新成为了研究者的关注点。 ​ 在模型优化中，常用到的几种学习率衰减方法有：分段常数衰减、多项式衰减、指数衰减、自然指数衰减、余弦衰减、线性余弦衰减、噪声线性余弦衰减</p>
<h4 id="1-9-1-分段常数衰减"><a href="#1-9-1-分段常数衰减" class="headerlink" title="1.9.1 分段常数衰减"></a>1.9.1 分段常数衰减</h4><p>分段常数衰减需要事先定义好的训练次数区间，在对应区间置不同的学习率的常数值，一般情况刚开始的学习率要大一些，之后要越来越小，要根据样本量的大小设置区间的间隔大小，样本量越大，区间间隔要小一点。下图即为分段常数衰减的学习率变化图，横坐标代表训练次数，纵坐标代表学习率。</p>
<p><img src="/imgs/deeplearning/ch3/learnrate1.png" srcset="/img/loading.gif" alt=""></p>
<h4 id="1-9-2-指数衰减"><a href="#1-9-2-指数衰减" class="headerlink" title="1.9.2 指数衰减"></a>1.9.2 指数衰减</h4><p>以指数衰减方式进行学习率的更新，学习率的大小和训练次数指数相关，其更新规则为：</p>
<script type="math/tex; mode=display">
decayed{\_}learning{\_}rate =learning{\_}rate*decay{\_}rate^{\frac{global{\_step}}{decay{\_}steps}}</script><p>这种衰减方式简单直接，收敛速度快，是最常用的学习率衰减方式，如下图所示，绿色的为学习率随训练次数的指数衰减方式，红色的即为分段常数衰减，它在一定的训练区间内保持学习率不变。</p>
<p><img src="/imgs/deeplearning/ch3/learnrate2.png" srcset="/img/loading.gif" alt=""></p>
<h4 id="1-9-3-自然指数衰减"><a href="#1-9-3-自然指数衰减" class="headerlink" title="1.9.3 自然指数衰减"></a>1.9.3 自然指数衰减</h4><p>它与指数衰减方式相似，不同的在于它的衰减底数是$e$，故而其收敛的速度更快，一般用于相对比较容易训练的网络，便于较快的收敛，其更新规则如下</p>
<script type="math/tex; mode=display">
decayed{\_}learning{\_}rate =learning{\_}rate*e^{\frac{-decay{\_rate}}{global{\_}step}}</script><p>下图为为分段常数衰减、指数衰减、自然指数衰减三种方式的对比图，红色的即为分段常数衰减图，阶梯型曲线。蓝色线为指数衰减图，绿色即为自然指数衰减图，很明可以看到自然指数衰减方式下的学习率衰减程度要大于一般指数衰减方式，有助于更快的收敛。</p>
<p><img src="/imgs/deeplearning/ch3/learnrate3.png" srcset="/img/loading.gif" alt=""></p>
<h4 id="1-9-4-多项式衰减"><a href="#1-9-4-多项式衰减" class="headerlink" title="1.9.4 多项式衰减"></a>1.9.4 多项式衰减</h4><p>应用多项式衰减的方式进行更新学习率，这里会给定初始学习率和最低学习率取值，然后将会按照给定的衰减方式将学习率从初始值衰减到最低值,其更新规则如下式所示。</p>
<script type="math/tex; mode=display">
global{\_}step=min(global{\_}step,decay{\_}steps)</script><script type="math/tex; mode=display">
decayed{\_}learning{\_}rate =(learning{\_}rate-end{\_}learning{\_}rate)* \left( 1-\frac{global{\_step}}{decay{\_}steps}\right)^{power} \\
 +end{\_}learning{\_}rate</script><p>需要注意的是，有两个机制，降到最低学习率后，到训练结束可以一直使用最低学习率进行更新，另一个是再次将学习率调高，使用 decay_steps 的倍数，取第一个大于 global_steps 的结果，如下式所示.它是用来防止神经网络在训练的后期由于学习率过小而导致的网络一直在某个局部最小值附近震荡，这样可以通过在后期增大学习率跳出局部极小值。</p>
<script type="math/tex; mode=display">
decay{\_}steps = decay{\_}steps*ceil \left( \frac{global{\_}step}{decay{\_}steps}\right)</script><p>如下图所示，红色线代表学习率降低至最低后，一直保持学习率不变进行更新，绿色线代表学习率衰减到最低后，又会再次循环往复的升高降低。</p>
<p><img src="/imgs/deeplearning/ch3/learnrate4.png" srcset="/img/loading.gif" alt=""></p>
<h4 id="1-9-5-余弦衰减"><a href="#1-9-5-余弦衰减" class="headerlink" title="1.9.5 余弦衰减"></a>1.9.5 余弦衰减</h4><p>余弦衰减就是采用余弦的相关方式进行学习率的衰减，衰减图和余弦函数相似。其更新机制如下式所示：</p>
<script type="math/tex; mode=display">
global{\_}step=min(global{\_}step,decay{\_}steps)</script><script type="math/tex; mode=display">
cosine{\_}decay=0.5*\left( 1+cos\left( \pi* \frac{global{\_}step}{decay{\_}steps}\right)\right)</script><script type="math/tex; mode=display">
decayed=(1-\alpha)*cosine{\_}decay+\alpha</script><script type="math/tex; mode=display">
decayed{\_}learning{\_}rate=learning{\_}rate*decayed</script><p>如下图所示，红色即为标准的余弦衰减曲线，学习率从初始值下降到最低学习率后保持不变。蓝色的线是线性余弦衰减方式曲线，它是学习率从初始学习率以线性的方式下降到最低学习率值。绿色噪声线性余弦衰减方式。</p>
<p><img src="/imgs/deeplearning/ch3/learnrate5.png" srcset="/img/loading.gif" alt=""></p>
<h2 id="二、卷积神经网络CNN"><a href="#二、卷积神经网络CNN" class="headerlink" title="二、卷积神经网络CNN"></a>二、卷积神经网络CNN</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">CNN层次结构</th>
<th style="text-align:center">输出尺寸</th>
<th style="text-align:left">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">输入层</td>
<td style="text-align:center">$W_1\times H_1\times 3$</td>
<td style="text-align:left">卷积网络的原始输入，可以是原始或预处理后的像素矩阵</td>
</tr>
<tr>
<td style="text-align:center">卷积层</td>
<td style="text-align:center">$W_1\times H_1\times K$</td>
<td style="text-align:left">参数共享、局部连接，利用平移不变性从全局特征图提取局部特征</td>
</tr>
<tr>
<td style="text-align:center">激活层</td>
<td style="text-align:center">$W_1\times H_1\times K$</td>
<td style="text-align:left">将卷积层的输出结果进行非线性映射</td>
</tr>
<tr>
<td style="text-align:center">池化层</td>
<td style="text-align:center">$W_2\times H_2\times K$</td>
<td style="text-align:left">进一步筛选特征，可以有效减少后续网络层次所需的参数量</td>
</tr>
<tr>
<td style="text-align:center">全连接层</td>
<td style="text-align:center">$(W_2 \cdot H_2 \cdot K)\times C$</td>
<td style="text-align:left">将多维特征展平为2维特征，通常低维度特征对应任务的学习目标（类别或回归值）</td>
</tr>
</tbody>
</table>
</div>
<div class="note note-info">
            <p>$W_1\times H_1\times 3$对应原始图像或经过预处理的像素值矩阵，3对应RGB图像的通道;$K$表示卷积层中卷积核（滤波器）的个数;$W_2\times H_2$ 为池化后特征图的尺度，在全局池化中尺度对应$1\times 1$;$(W_2 \cdot H_2 \cdot K)$是将多维特征压缩到1维之后的大小，$C$对应的则是图像类别个数。</p>
          </div>
<h3 id="2-1-输入层"><a href="#2-1-输入层" class="headerlink" title="2.1 输入层"></a>2.1 输入层</h3><p>输入层(Input Layer)通常是输入卷积神经网络的原始数据或经过预处理的数据，可以是图像识别领域中原始三维的多彩图像，也可以是音频识别领域中经过傅利叶变换的二维波形数据，甚至是自然语言处理中一维表示的句子向量。以图像分类任务为例，输入层输入的图像一般包含RGB三个通道，是一个由长宽分别为$H$和$W$组成的3维像素值矩阵$H\times W \times 3$，卷积网络会将输入层的数据传递到一系列卷积、池化等操作进行特征提取和转化，最终由全连接层对特征进行汇总和结果输出。根据计算能力、存储大小和模型结构的不同，卷积神经网络每次可以批量处理的图像个数不尽相同，若指定输入层接收到的图像个数为$N$，则输入层的输出数据为$N\times H\times W\times 3$。</p>
<h3 id="2-2-卷积层"><a href="#2-2-卷积层" class="headerlink" title="2.2 卷积层"></a>2.2 卷积层</h3><p>卷积层(Convolution Layer)通常用作对输入层输入数据进行特征提取，通过卷积核矩阵对原始数据中隐含关联性的一种抽象。卷积操作原理上其实是对两张像素矩阵进行点乘求和的数学操作，其中一个矩阵为输入的数据矩阵，另一个矩阵则为卷积核（滤波器或特征矩阵），求得的结果表示为原始图像中提取的特定局部特征。图5.1表示卷积操作过程中的不同填充策略，上半部分采用零填充，下半部分采用有效卷积（舍弃不能完整运算的边缘部分）。</p>
<p><img src="/imgs/deeplearning/ch5/convolution.png" srcset="/img/loading.gif" alt="conv-same"></p>
<h4 id="2-2-1-局部连接"><a href="#2-2-1-局部连接" class="headerlink" title="2.2.1 局部连接"></a>2.2.1 局部连接</h4><p>我们首先了解一个概念，感受野，即每个神经元仅与输入神经元相连接的一块区域。<br>在图像卷积操作中，神经元在空间维度上是局部连接，但在深度上是全连接。局部连接的思想，是受启发于生物学里的视觉系统结构，视觉皮层的神经元就是仅用局部接受信息。对于二维图像，局部像素关联性较强。这种局部连接保证了训练后的滤波器能够对局部特征有最强的响应，使神经网络可以提取数据的局部特征；<br>下图是一个很经典的图示，左边是全连接，右边是局部连接。</p>
<p><img src="/imgs/deeplearning/ch5/5.27.1.png" srcset="/img/loading.gif" alt="image"></p>
<p>对于一个1000 × 1000的输入图像而言，如果下一个隐藏层的神经元数目为10^6个，采用全连接则有1000 × 1000 × 10^6 = 10^12个权值参数，如此巨大的参数量几乎难以训练；而采用局部连接，隐藏层的每个神经元仅与图像中10 × 10的局部图像相连接，那么此时的权值参数数量为10 × 10 × 10^6 = 10^8，将直接减少4个数量级。</p>
<h4 id="2-2-2-权值共享"><a href="#2-2-2-权值共享" class="headerlink" title="2.2.2 权值共享"></a>2.2.2 权值共享</h4><p>权值共享，即计算同一深度的神经元时采用的卷积核参数是共享的。权值共享在一定程度上讲是有意义的，是由于在神经网络中，提取的底层边缘特征与其在图中的位置无关。但是在另一些场景中是无意的，如在人脸识别任务，我们期望在不同的位置学到不同的特征。</p>
<p>需要注意的是，权重只是对于同一深度切片的神经元是共享的。在卷积层中，通常采用多组卷积核提取不同的特征，即对应的是不同深度切片的特征，而不同深度切片的神经元权重是不共享。相反，偏置这一权值对于同一深度切片的所有神经元都是共享的。</p>
<p>权值共享带来的好处是大大降低了网络的训练难度。如下图，假设在局部连接中隐藏层的每一个神经元连接的是一个10 × 10的局部图像，因此有10 × 10个权值参数，将这10 × 10个权值参数共享给剩下的神经元，也就是说隐藏层中10^6个神经元的权值参数相同，那么此时不管隐藏层神经元的数目是多少，需要训练的参数就是这 10 × 10个权值参数（也就是卷积核的大小）。</p>
<p><img src="/imgs/deeplearning/ch5/5.27.2.png" srcset="/img/loading.gif" alt="image"></p>
<p>这里就体现了卷积神经网络的奇妙之处，使用少量的参数，却依然能有非常出色的性能。上述仅仅是提取图像一种特征的过程。如果要多提取出一些特征，可以增加多个卷积核，不同的卷积核能够得到图像不同尺度下的特征，称之为特征图（feature map）。</p>
<h4 id="2-2-3-卷积层参数"><a href="#2-2-3-卷积层参数" class="headerlink" title="2.2.3 卷积层参数"></a>2.2.3 卷积层参数</h4><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">参数名</th>
<th style="text-align:left">作用</th>
<th style="text-align:left">常见设置</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">卷积核大小 (Kernel Size)</td>
<td style="text-align:left">卷积核的大小定义了卷积的感受野</td>
<td style="text-align:left">在过去常设为5，如LeNet-5；现在多设为3，通过堆叠$3\times3$的卷积核来达到更大的感受域</td>
</tr>
<tr>
<td style="text-align:center">卷积核步长 (Stride)</td>
<td style="text-align:left">定义了卷积核在卷积过程中的步长</td>
<td style="text-align:left">常见设置为1，表示滑窗距离为1，可以覆盖所有相邻位置特征的组合；当设置为更大值时相当于对特征组合降采样</td>
</tr>
<tr>
<td style="text-align:center">填充方式 (Padding)</td>
<td style="text-align:left">在卷积核尺寸不能完美匹配输入的图像矩阵时需要进行一定的填充策略</td>
<td style="text-align:left">设置为’SAME’表示对不足卷积核大小的边界位置进行某种填充（通常零填充）以保证卷积输出维度与与输入维度一致；当设置为’VALID’时则对不足卷积尺寸的部分进行舍弃，输出维度就无法保证与输入维度一致</td>
</tr>
<tr>
<td style="text-align:center">输入通道数 (In Channels)</td>
<td style="text-align:left">指定卷积操作时卷积核的深度</td>
<td style="text-align:left">默认与输入的特征矩阵通道数（深度）一致；在某些压缩模型中会采用通道分离的卷积方式</td>
</tr>
<tr>
<td style="text-align:center">输出通道数 (Out Channels)</td>
<td style="text-align:left">指定卷积核的个数</td>
<td style="text-align:left">若设置为与输入通道数一样的大小，可以保持输入输出维度的一致性；若采用比输入通道数更小的值，则可以减少整体网络的参数量</td>
</tr>
</tbody>
</table>
</div>
<div class="note note-info">
            <p>卷积操作维度变换公式：</p><script type="math/tex; mode=display">O_d =\begin{cases} \lceil \frac{(I_d - k_{size})+ 1)}{s}\rceil ,& \text{padding=VALID}\\ \lceil \frac{I_d}{s}\rceil,&\text{padding=SAME} \end{cases}</script><p>其中，$I_d$为输入维度，$O_d$为输出维度，$k_{size}$为卷积核大小，$s$为步长</p>
          </div>
<h3 id="2-3-激活层"><a href="#2-3-激活层" class="headerlink" title="2.3 激活层"></a>2.3 激活层</h3><p>激活层(Activation Layer)负责对卷积层抽取的特征进行激活，由于卷积操作是由输入矩阵与卷积核矩阵进行相差的线性变化关系，需要激活层对其进行非线性的映射。激活层主要由激活函数组成，即在卷积层输出结果的基础上嵌套一个非线性函数，让输出的特征图具有非线性关系。卷积网络中通常采用ReLU来充当激活函数（还包括tanh和sigmoid等）。</p>
<h4 id="2-3-1-sigmoid-激活函数"><a href="#2-3-1-sigmoid-激活函数" class="headerlink" title="2.3.1 sigmoid 激活函数"></a>2.3.1 sigmoid 激活函数</h4><p>函数的定义为：$ f(x) = \frac{1}{1 + e^{-x}} $，其值域为 $ (0,1) $。</p>
<p>函数图像如下：</p>
<p><img src="/imgs/deeplearning/ch3/3-26.png" srcset="/img/loading.gif" alt=""></p>
<h4 id="2-3-2-tanh激活函数"><a href="#2-3-2-tanh激活函数" class="headerlink" title="2.3.2 tanh激活函数"></a>2.3.2 tanh激活函数</h4><p>函数的定义为：$ f(x) = tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} $，值域为 $ (-1,1) $。</p>
<p>函数图像如下：</p>
<p><img src="/imgs/deeplearning/ch3/3-27.png" srcset="/img/loading.gif" alt=""></p>
<h4 id="2-3-3-Relu激活函数"><a href="#2-3-3-Relu激活函数" class="headerlink" title="2.3.3 Relu激活函数"></a>2.3.3 Relu激活函数</h4><p>函数的定义为：$ f(x) = max(0, x) $  ，值域为 $ [0,+∞) $；</p>
<p>函数图像如下：</p>
<p><img src="/imgs/deeplearning/ch3/3-28.png" srcset="/img/loading.gif" alt=""></p>
<h4 id="2-3-4-Leak-Relu激活函数"><a href="#2-3-4-Leak-Relu激活函数" class="headerlink" title="2.3.4 Leak Relu激活函数"></a>2.3.4 Leak Relu激活函数</h4><p>函数定义为： $ f(x) =  \left\lbrace<br>   \begin{aligned}<br>   ax, \quad x<0 \\
   x, \quad x>0<br>   \end{aligned}<br>   \right. $，值域为 $ (-\infty,+\infty) $。 </p>
<p>图像如下（$ a = 0.5 $）：</p>
<p><img src="/imgs/deeplearning/ch3/3-29.png" srcset="/img/loading.gif" alt=""></p>
<h4 id="2-3-5-SoftPlus激活函数"><a href="#2-3-5-SoftPlus激活函数" class="headerlink" title="2.3.5 SoftPlus激活函数"></a>2.3.5 SoftPlus激活函数</h4><p>函数的定义为：$ f(x) = ln( 1 + e^x) $，值域为 $ (0,+\infty) $。</p>
<p>函数图像如下:</p>
<p><img src="/imgs/deeplearning/ch3/3-30.png" srcset="/img/loading.gif" alt=""></p>
<h4 id="2-3-6-softmax函数"><a href="#2-3-6-softmax函数" class="headerlink" title="2.3.6 softmax函数"></a>2.3.6 softmax函数</h4><p>函数定义为： $ \sigma(z)_j = \frac{e^{z_j}}{\sum_{k=1}^K e^{z_k}} $。</p>
<p>Softmax 多用于多分类神经网络输出。</p>
<h3 id="2-4-池化层-汇合层"><a href="#2-4-池化层-汇合层" class="headerlink" title="2.4 池化层(汇合层)"></a>2.4 池化层(汇合层)</h3><p>池化层又称为降采样层(Downsampling Layer)，作用是对感受域内的特征进行筛选，提取区域内最具代表性的特征，能够有效地降低输出特征尺度，进而减少模型所需要的参数量。按操作类型通常分为最大池化(Max Pooling)、平均池化(Average Pooling)和求和池化(Sum Pooling)，它们分别提取感受域内最大、平均与总和的特征值作为输出，最常用的是最大池化。</p>
<p><img src="/imgs/deeplearning/ch5/5.27.3.png" srcset="/img/loading.gif" alt="image"></p>
<h3 id="2-5-全连接层"><a href="#2-5-全连接层" class="headerlink" title="2.5 全连接层"></a>2.5 全连接层</h3><p>全连接层(Full Connected Layer)负责对卷积神经网络学习提取到的特征进行汇总，将多维的特征输入映射为二维的特征输出，高维表示样本批次，低位常常对应任务目标。</p>
<h2 id="三、深度学习在计算机视觉中的应用"><a href="#三、深度学习在计算机视觉中的应用" class="headerlink" title="三、深度学习在计算机视觉中的应用"></a>三、深度学习在计算机视觉中的应用</h2><h3 id="3-1-图像识别"><a href="#3-1-图像识别" class="headerlink" title="3.1 图像识别"></a>3.1 图像识别</h3><p>计算机视觉中关于图像识别有四大类任务：</p>
<p><strong>分类-Classification</strong>：解决“是什么？”的问题，即给定一张图片或一段视频判断里面包含什么类别的目标。</p>
<p><strong>定位-Location</strong>：解决“在哪里？”的问题，即定位出这个目标的的位置。</p>
<p><strong>检测-Detection</strong>：解决“是什么？在哪里？”的问题，即定位出这个目标的的位置并且知道目标物是什么。</p>
<p><strong>分割-Segmentation</strong>：分为实例的分割（Instance-level）和场景分割（Scene-level），解决“每一个像素属于哪个目标物或场景”的问题。</p>
<p><img src="/imgs/deeplearning/ch8/8.1.1.png" srcset="/img/loading.gif" alt="图像识别四大类任务，图像来源于cs231n 2016课件Lecture 8"></p>
<h4 id="3-1-1-手写数字识别-MNIST"><a href="#3-1-1-手写数字识别-MNIST" class="headerlink" title="3.1.1 手写数字识别 MNIST"></a>3.1.1 手写数字识别 MNIST</h4><p><img src="/imgs/deeplearning/mnist.jpeg" srcset="/img/loading.gif" alt=""></p>
<h4 id="3-1-2-图像分割"><a href="#3-1-2-图像分割" class="headerlink" title="3.1.2 图像分割"></a>3.1.2 图像分割</h4><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/imgs/deeplearning/seg1.jpg" srcset="/img/loading.gif" alt=""></div><div class="group-image-wrap"><img src="/imgs/deeplearning/seg2.jpg" srcset="/img/loading.gif" alt=""></div></div></div>
<h4 id="3-1-3-目标检测"><a href="#3-1-3-目标检测" class="headerlink" title="3.1.3 目标检测"></a>3.1.3 目标检测</h4><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/imgs/deeplearning/det1.jpg" srcset="/img/loading.gif" alt=""></div><div class="group-image-wrap"><img src="/imgs/deeplearning/det3.png" srcset="/img/loading.gif" alt=""></div></div></div>
<h4 id="3-1-4-人脸识别"><a href="#3-1-4-人脸识别" class="headerlink" title="3.1.4 人脸识别"></a>3.1.4 人脸识别</h4><h5 id="3-1-4-1-FaceNet"><a href="#3-1-4-1-FaceNet" class="headerlink" title="3.1.4.1 FaceNet"></a>3.1.4.1 FaceNet</h5><p><img src="/imgs/deeplearning/facenet.png" srcset="/img/loading.gif" alt=""></p>
<h5 id="3-1-4-2-OpenFace"><a href="#3-1-4-2-OpenFace" class="headerlink" title="3.1.4.2 OpenFace"></a>3.1.4.2 OpenFace</h5><p><img src="/imgs/deeplearning/openface.png" srcset="/img/loading.gif" alt=""></p>
<h5 id="3-1-4-3-VRN"><a href="#3-1-4-3-VRN" class="headerlink" title="3.1.4.3 VRN"></a>3.1.4.3 VRN</h5><p><img src="/imgs/deeplearning/vrn.png" srcset="/img/loading.gif" alt=""></p>
<h3 id="3-2-立体匹配-Stereo-Match"><a href="#3-2-立体匹配-Stereo-Match" class="headerlink" title="3.2 立体匹配 Stereo Match"></a>3.2 立体匹配 Stereo Match</h3><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/imgs/deeplearning/stereo/Adirondack_left.png" srcset="/img/loading.gif" alt=""></div><div class="group-image-wrap"><img src="/imgs/deeplearning/stereo/Adirondack.png" srcset="/img/loading.gif" alt=""></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="/imgs/deeplearning/stereo/ArtL_left.png" srcset="/img/loading.gif" alt=""></div><div class="group-image-wrap"><img src="/imgs/deeplearning/stereo/ArtL.png" srcset="/img/loading.gif" alt=""></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="/imgs/deeplearning/stereo/Motorcycle_left.png" srcset="/img/loading.gif" alt=""></div><div class="group-image-wrap"><img src="/imgs/deeplearning/stereo/Motorcycle.png" srcset="/img/loading.gif" alt=""></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="/imgs/deeplearning/stereo/Recycle_left.png" srcset="/img/loading.gif" alt=""></div><div class="group-image-wrap"><img src="/imgs/deeplearning/stereo/Recycle.png" srcset="/img/loading.gif" alt=""></div></div></div>
<h3 id="3-3-图像复原-Image-Restoration"><a href="#3-3-图像复原-Image-Restoration" class="headerlink" title="3.3 图像复原 Image Restoration"></a>3.3 图像复原 Image Restoration</h3><h4 id="3-3-1-denoising"><a href="#3-3-1-denoising" class="headerlink" title="3.3.1 denoising"></a>3.3.1 denoising</h4><p><img src="/imgs/deeplearning/denoising.png" srcset="/img/loading.gif" alt=""></p>
<h4 id="3-3-2-super-resolution"><a href="#3-3-2-super-resolution" class="headerlink" title="3.3.2 super resolution"></a>3.3.2 super resolution</h4><p><img src="/imgs/deeplearning/super-resolution.png" srcset="/img/loading.gif" alt=""></p>
<h4 id="3-3-3-inpainting"><a href="#3-3-3-inpainting" class="headerlink" title="3.3.3 inpainting"></a>3.3.3 inpainting</h4><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/imgs/deeplearning/640.jpeg" srcset="/img/loading.gif" alt=""></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="/imgs/deeplearning/inpainting.jpeg" srcset="/img/loading.gif" alt=""></div></div></div>
<h3 id="3-4-其他"><a href="#3-4-其他" class="headerlink" title="3.4 其他"></a>3.4 其他</h3><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/imgs/deeplearning/rmvsnet1.png" srcset="/img/loading.gif" alt=""></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="/imgs/deeplearning/rmvsnet2.png" srcset="/img/loading.gif" alt=""></div></div></div>
<h2 id="四、深度学习框架"><a href="#四、深度学习框架" class="headerlink" title="四、深度学习框架"></a>四、深度学习框架</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">开发框架</th>
<th style="text-align:center">开发语言</th>
<th style="text-align:center">支持平台</th>
<th style="text-align:center">自动求导</th>
<th style="text-align:center">预训练模型</th>
<th style="text-align:center">CNN开发</th>
<th style="text-align:center">RNN开发</th>
<th style="text-align:center">单机多卡并行</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Caffe</td>
<td style="text-align:center">C++</td>
<td style="text-align:center">Linux,Mac OS X,Windows</td>
<td style="text-align:center">不支持</td>
<td style="text-align:center">提供</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">支持</td>
</tr>
<tr>
<td style="text-align:center">Keras</td>
<td style="text-align:center">Python</td>
<td style="text-align:center">Linux,Mac OS X,Windows</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">提供</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">不支持</td>
</tr>
<tr>
<td style="text-align:center">MXNet</td>
<td style="text-align:center">C++</td>
<td style="text-align:center">Linux,Mac OS X,Windows</td>
<td style="text-align:center">不支持</td>
<td style="text-align:center">提供</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">支持</td>
</tr>
<tr>
<td style="text-align:center">TensorFlow</td>
<td style="text-align:center">C++,Python</td>
<td style="text-align:center">Linux,Mac OS X,Windows</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">提供</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">支持</td>
</tr>
<tr>
<td style="text-align:center">Theano</td>
<td style="text-align:center">Python</td>
<td style="text-align:center">Cross-platform</td>
<td style="text-align:center">不支持</td>
<td style="text-align:center">不提供</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">不支持</td>
</tr>
<tr>
<td style="text-align:center">Pytorch</td>
<td style="text-align:center">Python</td>
<td style="text-align:center">Linux,Mac OS X</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">提供</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">支持</td>
</tr>
</tbody>
</table>
</div>
<h3 id="4-1-常用框架的特点"><a href="#4-1-常用框架的特点" class="headerlink" title="4.1 常用框架的特点"></a>4.1 常用框架的特点</h3><h4 id="4-1-1-Caffe"><a href="#4-1-1-Caffe" class="headerlink" title="4.1.1 Caffe"></a>4.1.1 Caffe</h4><p>Caffe是一个广为人知、广泛应用侧重计算机视觉方面的深度学习库，由加州大学伯克利分校BVLC组开发，总结来说， Caffe 有以下优缺点：</p>
<ul>
<li>✓ 适合前馈网络和图像处理；</li>
<li>✓ 适合微调已有的网络模型；</li>
<li>✓ 训练已有网络模型无需编写任何代码；</li>
<li>✓ 提供方便的Python和Matlab接口；</li>
<li>✗ 可单机多卡，但不支持多机多卡；</li>
<li>✗ 需要用C++/CUDA编写新的GPU层；</li>
<li>✗ 不适合循环网络；</li>
<li>✗ 用于大型网络（如，GoogLeNet\ResNet）时过于繁琐；</li>
<li>✗ 扩展性稍差，代码有些不够精简；</li>
<li>✗ 不提供商业支持；</li>
<li>✗ 框架更新缓慢，可能之后不再更新。</li>
</ul>
<h4 id="4-1-2-Keras"><a href="#4-1-2-Keras" class="headerlink" title="4.1.2 Keras"></a>4.1.2 Keras</h4><p>Keras由谷歌软件工程师Francois Chollet开发，是一个基于Theano和TensorFlow的深度学习库，具有一个受Torch启发、较为直观的API。其优缺点如下：</p>
<ul>
<li>✓ 受Torch启发的直观API;</li>
<li>✓ 可使用Theano、TensorFlow和Deeplearning4j后端；</li>
<li>✓ 支持自动求导；</li>
<li>✓ 框架更新速度快</li>
</ul>
<h4 id="4-1-3-TensorFlow"><a href="#4-1-3-TensorFlow" class="headerlink" title="4.1.3 TensorFlow"></a>4.1.3 TensorFlow</h4><p>TensorFlow是Google负责开发的用Python API编写，通过C/C++引擎加速的深度学习框架，是目前受关注最多的深度学习框架。它使用数据流图集成深度学习中最常见的单元，并支持许多最新的CNN网络结构以及不同设置的RNN。其优缺点为：</p>
<ul>
<li>✓ 具备不局限于深度学习的多种用途，还有支持强化学习和其他算法的工具；</li>
<li>✓ 跨平台运行能力强；</li>
<li>✓ 支持自动求导；</li>
<li>✗ 运行明显比其他框架慢；</li>
<li>✗ 不提供商业支持。</li>
</ul>
<h4 id="4-1-4-Torch"><a href="#4-1-4-Torch" class="headerlink" title="4.1.4 Torch"></a>4.1.4 Torch</h4><p>Torch是用Lua编写带API的科学计算框架，支持机器学习算法。Facebook和Twitter等大型科技公司使用Torch的某些版本，由内部团队专门负责定制自己的深度学习平台。其优缺点如下：</p>
<ul>
<li>✓ 大量模块化组件，容易组合；</li>
<li>✓ 易编写新的网络层；</li>
<li>✓ 支持丰富的预训练模型；</li>
<li>✓ Pytorch为Torch提供了更便利的接口；</li>
<li>✗ 使用Lua语言需要学习成本；</li>
<li>✗ 文档质量参差不齐；</li>
<li>✗ 一般需要自己编写训练代码（即插即用相对较少）。</li>
</ul>

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" target="_blank" rel="nofollow noopener noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2020/06/09/hello-world/">
                        <span class="hidden-mobile">Hello World</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

            
              <!-- Comments -->
              <div class="comments" id="comments">
                
                
  <div id="vcomments"></div>
  <script defer src="https://cdn.staticfile.org/valine/1.4.14/Valine.min.js" ></script>

  <script type="text/javascript">
    var oldLoadVa = window.onload;
    window.onload = function () {
      oldLoadVa && oldLoadVa();

      new Valine({
        el: "#vcomments",
        app_id: "KKrnC7r3XXGKwp1TgYmCOTIW-gzGzoHsz",
        app_key: "gxzi3YsuzYzUxxC8VbrJtekm",
        placeholder: "说点什么",
        path: window.location.pathname,
        avatar: "retro",
        meta: ["nick","mail","link"],
        pageSize: "10",
        lang: "zh-CN",
        highlight: false,
        recordIP: false,
        serverURLs: "",
      });
    };
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://valine.js.org" target="_blank" rel="nofollow noopener noopener">comments
      powered by Valine.</a></noscript>


              </div>
            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    

    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/main.js" ></script>


  <script  src="/js/lazyload.js" ></script>



  
  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '.post-content',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>





  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>






<!-- Plugins -->



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "深度学习入门&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.staticfile.org/mathjax/3.0.5/es5/tex-svg.js" ></script>

  














</body>
</html>
