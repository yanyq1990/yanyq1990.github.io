<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="yanyq">
  <meta name="keywords" content="">
  <title>深度学习入门 - </title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/github-gist.min.css" />


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_fmb4a04yx8h.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_ijqayz9ro8k.css">




<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


<meta name="generator" content="Hexo 4.2.1"></head>


<body>
  <header style="height: 100vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Fluid</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">
              <i class="iconfont icon-home-fill"></i>
              首页</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">
              <i class="iconfont icon-archive-fill"></i>
              归档</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">
              <i class="iconfont icon-category-fill"></i>
              分类</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">
              <i class="iconfont icon-tags-fill"></i>
              标签</a>
          </li>
        
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">
              <i class="iconfont icon-user-fill"></i>
              关于</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
                <div class="mt-3 post-meta">
                  <i class="iconfont icon-date-fill" aria-hidden="true"></i>
                  <time datetime="2020-06-09 11:44">
                    2020年6月9日 中午
                  </time>
                </div>
              

              <div class="mt-1">
                
                  
                  <span class="post-meta mr-2">
                    <i class="iconfont icon-chart"></i>
                    9.6k 字
                  </span>
                

                
                  
                  <span class="post-meta mr-2">
                      <i class="iconfont icon-clock-fill"></i>
                    
                    
                    107
                     分钟
                  </span>
                

                
              </div>
            
          </div>

          
            <div class="scroll-down-bar">
              <i class="iconfont icon-arrowdown"></i>
            </div>
          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <div class="post-content mx-auto" id="post">
            
            <article class="markdown-body">
              <h1 id="深度学习入门"><a href="#深度学习入门" class="headerlink" title="深度学习入门"></a>深度学习入门</h1><p>颜远青 2020年06月09日</p>
<h2 id="一、深度学习基础"><a href="#一、深度学习基础" class="headerlink" title="一、深度学习基础"></a>一、深度学习基础</h2><h3 id="1-1-深度学习与机器学习的差异"><a href="#1-1-深度学习与机器学习的差异" class="headerlink" title="1.1 深度学习与机器学习的差异"></a>1.1 深度学习与机器学习的差异</h3><p><strong>机器学习</strong>：利用计算机、概率论、统计学等知识，输入数据，让计算机学会新知识。机器学习的过程，就是训练数据去优化目标函数。</p>
<p><strong>深度学习</strong>：是一种特殊的机器学习，具有强大的能力和灵活性。它通过学习将世界表示为嵌套的层次结构，每个表示都与更简单的特征相关，而抽象的表示则用于计算更抽象的表示。</p>
<p>传统的机器学习需要<strong>定义一些手工特征</strong>，从而<strong>有目的的去提取目标信息</strong>， 非常依赖任务的特异性以及设计特征的专家经验。而深度学习可以<strong>从大数据中先学习简单的特征，并从其逐渐学习到更为复杂抽象的深层特征，不依赖人工的特征工程</strong>，这也是深度学习在大数据时代受欢迎的一大原因。</p>
<h3 id="1-2-感知机与多层感知机"><a href="#1-2-感知机与多层感知机" class="headerlink" title="1.2 感知机与多层感知机"></a>1.2 感知机与多层感知机</h3><p>神经网络类型众多，其中最为重要的是多层感知机。为了详细地描述神经网络，我们先从最简单的神经网络说起。</p>
<p><strong>感知机</strong></p>
<p>多层感知机中的特征神经元模型称为感知机，由<em>Frank Rosenblatt</em>于1957年发明。</p>
<p>简单的感知机如下图所示：</p>
<p><img src="/imgs/deeplearning/ch3/3-1.png" srcset="/img/loading.gif" alt=""></p>
<p>其中$x_1$，$x_2$，$x_3$为感知机的输入，其输出为：</p>
<script type="math/tex; mode=display">
output = \left\{
\begin{aligned}
0, \quad if \ \ \sum_i w_i x_i \leqslant threshold \\
1, \quad if \ \ \sum_i w_i x_i > threshold
\end{aligned}
\right.</script><p>假如把感知机想象成一个加权投票机制，比如 3 位评委给一个歌手打分，打分分别为$ 4 $分、$1$ 分、$-3 $分，这$ 3$ 位评分的权重分别是 $1、3、2$，则该歌手最终得分为 $4 \times 1 + 1 \times 3 + (-3) \times 2 = 1$ 。按照比赛规则，选取的 $threshold$ 为 $3$，说明只有歌手的综合评分大于$ 3$ 时，才可顺利晋级。对照感知机，该选手被淘汰，因为：</p>
<script type="math/tex; mode=display">
\sum_i w_i x_i < threshold=3, output = 0</script><p>用 $-b$  代替 $threshold$，输出变为：</p>
<script type="math/tex; mode=display">
output = \left\{
\begin{aligned}
0, \quad if \ \ \boldsymbol{w} \cdot \boldsymbol{x} + b \leqslant 0 \\
1, \quad if \ \ \boldsymbol{w} \cdot \boldsymbol{x} + b > 0
\end{aligned}
\right.</script><p>设置合适的  $\boldsymbol{x}$  和  $b$ ，一个简单的感知机单元的与非门表示如下：</p>
<p><img src="/imgs/deeplearning/ch3/3-2.png" srcset="/img/loading.gif" alt=""></p>
<p>当输入为 $0$，$1$ 时，感知机输出为 $ 0 \times (-2) + 1 \times (-2) + 3 = 1$。</p>
<p>复杂一些的感知机由简单的感知机单元组合而成：</p>
<p><img src="/imgs/deeplearning/ch3/3-3.png" srcset="/img/loading.gif" alt=""></p>
<p><strong>多层感知机</strong></p>
<p>多层感知机由感知机推广而来，最主要的特点是有多个神经元层，因此也叫深度神经网络。相比于单独的感知机，多层感知机的第 $ i $ 层的每个神经元和第 $ i-1 $ 层的每个神经元都有连接。</p>
<p><img src="/imgs/deeplearning/ch3/3.1.1.5.png" srcset="/img/loading.gif" alt=""></p>
<p>输出层可以不止有$ 1$ 个神经元。隐藏层可以只有$ 1$ 层，也可以有多层。输出层为多个神经元的神经网络例如下图所示：</p>
<p><img src="/imgs/deeplearning/ch3/3.1.1.6.png" srcset="/img/loading.gif" alt=""></p>
<h3 id="1-3-前向传播与反向传播"><a href="#1-3-前向传播与反向传播" class="headerlink" title="1.3 前向传播与反向传播"></a>1.3 前向传播与反向传播</h3><p>神经网络的计算主要有两种：前向传播（foward propagation, FP）作用于每一层的输入，通过逐层计算得到输出结果；反向传播（backward propagation, BP）作用于网络的输出，通过计算梯度由深到浅更新网络参数。</p>
<p><strong>前向传播</strong></p>
<p><img src="/imgs/deeplearning/ch3/3.2.1.1.png" srcset="/img/loading.gif" alt=""></p>
<p>假设上一层结点 $ i,j,k,… $ 等一些结点与本层的结点 $ w $ 有连接，那么结点 $ w $ 的值怎么算呢？就是通过上一层的 $ i,j,k,… $ 等结点以及对应的连接权值进行加权和运算，最终结果再加上一个偏置项（图中为了简单省略了），最后在通过一个非线性函数（即激活函数），如 $ReLu$，$sigmoid$ 等函数，最后得到的结果就是本层结点 $ w $ 的输出。 </p>
<p>最终不断的通过这种方法一层层的运算，得到输出层结果。</p>
<p><strong>反向传播</strong></p>
<p><img src="/imgs/deeplearning/ch3/3.2.1.2.png" srcset="/img/loading.gif" alt=""></p>
<p>由于我们前向传播最终得到的结果，以分类为例，最终总是有误差的，那么怎么减少误差呢，当前应用广泛的一个算法就是梯度下降算法，但是求梯度就要求偏导数，下面以图中字母为例讲解一下：</p>
<p>设最终误差为 $ E $且输出层的激活函数为线性激活函数，对于输出那么 $ E $ 对于输出节点 $ y_l $ 的偏导数是 $ y_l - t_l $，其中 $ t_l $ 是真实值，$ \frac{\partial y_l}{\partial z_l} $ 是指上面提到的激活函数，$ z_l $ 是上面提到的加权和，那么这一层的 $ E $ 对于 $ z_l $ 的偏导数为 $ \frac{\partial E}{\partial z_l} = \frac{\partial E}{\partial y_l} \frac{\partial y_l}{\partial z_l} $。同理，下一层也是这么计算，只不过 $ \frac{\partial E}{\partial y_k} $ 计算方法变了，一直反向传播到输入层，最后有 $ \frac{\partial E}{\partial x_i} = \frac{\partial E}{\partial y_j} \frac{\partial y_j}{\partial z_j} $，且 $ \frac{\partial z_j}{\partial x_i} = w_i j $。然后调整这些过程中的权值，再不断进行前向传播和反向传播的过程，最终得到一个比较好的结果。</p>
<h3 id="1-4-标量、向量、矩阵、张量"><a href="#1-4-标量、向量、矩阵、张量" class="headerlink" title="1.4 标量、向量、矩阵、张量"></a>1.4 标量、向量、矩阵、张量</h3><p><strong>标量（scalar）</strong><br>一个标量表示一个单独的数，它不同于线性代数中研究的其他大部分对象（通常是多个数的数组）。我们用斜体表示标量。标量通常被赋予小写的变量名称。 </p>
<p><strong>向量（vector）</strong><br>一个向量表示一组有序排列的数。通过次序中的索引，我们可以确定每个单独的数。通常我们赋予向量粗体的小写变量名称，比如xx。向量中的元素可以通过带脚标的斜体表示。向量$X$的第一个元素是$X_1$，第二个元素是$X_2$，以此类推。我们也会注明存储在向量中的元素的类型（实数、虚数等）。</p>
<p><strong>矩阵（matrix）</strong><br>矩阵是具有相同特征和纬度的对象的集合，表现为一张二维数据表。其意义是一个对象表示为矩阵中的一行，一个特征表示为矩阵中的一列，每个特征都有数值型的取值。通常会赋予矩阵粗体的大写变量名称，比如$A$。</p>
<p><strong>张量（tensor）</strong><br>在某些情况下，我们会讨论坐标超过两维的数组。一般地，一个数组中的元素分布在若干维坐标的规则网格中，我们将其称之为张量。使用 $A$ 来表示张量“A”。张量$A$中坐标为$(i,j,k)$的元素记作$A_{(i,j,k)}$。 </p>
<h3 id="1-5-训练集、验证集与测试集"><a href="#1-5-训练集、验证集与测试集" class="headerlink" title="1.5 训练集、验证集与测试集"></a>1.5 训练集、验证集与测试集</h3><p><strong>训练、验证、测试集</strong>是非常重要的三个内容。</p>
<ul>
<li><strong>训练集</strong>：用于模型训练的样本集合,主要用来训练神经网络中的参数,样本占用量是最大的;</li>
<li><strong>验证集</strong>：用于训练过程中的模型性能评价，跟着性能评价才能更好的调参；</li>
<li><strong>测试集</strong>：用于最终模型的一次最终评价，直接反应了模型的性能。</li>
</ul>
<p><strong>训练集、验证集和测试集的划分</strong></p>
<ul>
<li>在样本量有限的情况下，有时候会把验证集和测试集合并。实际中，若划分为三类，那么<strong>训练集:验证集:测试集=6:2:2</strong>；若是两类，则<strong>训练集：验证集=7:3</strong>。这里需要主要在数据量不够多的情况，验证集和测试集需要占的数据比例比较多，以充分了解模型的泛化性。</li>
<li>在海量样本的情况下，这种情况在目前深度学习中会比较常见。此时由于数据量巨大，我们不需要将过多的数据用于验证和测试集。例如拥有1百万样本时，我们按<strong>训练集:验证集:测试集=98:1:1</strong>的比例划分，1%的验证和1%的测试集都已经拥有了1万个样本。这已足够验证模型性能了。</li>
</ul>
<p>此外，三个数据集的划分不是一次就可以的，若调试过程中发现，三者得到的性能评价差异很大时，可以重新划分以确定是数据集划分的问题导致还是由模型本身导致的。其次，若评价指标发生变化，而导致模型性能差异在三者上很大时，同样可重新划分确认排除数据问题，以方便进一步的优化。</p>
<h3 id="1-6-训练误差与测试误差-泛化误差"><a href="#1-6-训练误差与测试误差-泛化误差" class="headerlink" title="1.6 训练误差与测试误差(泛化误差)"></a>1.6 训练误差与测试误差(泛化误差)</h3><p><strong>训练误差</strong>:模型在训练集上的误差平均值，度量了模型对训练集拟合的情况。训练误差大说明对训练集特性学习得不够，训练误差太小说明过度学习了训练集特性，容易发生过拟合。</p>
<p><strong>测试误差</strong>:模型在测试集上的误差平均值，度量了模型的泛化能力。在实践中，希望测试误差越小越好。</p>
<h3 id="1-7-欠拟合与过拟合"><a href="#1-7-欠拟合与过拟合" class="headerlink" title="1.7 欠拟合与过拟合"></a>1.7 欠拟合与过拟合</h3><p><strong>欠拟合</strong>就是说模型尚未学习完整训练集实例的普适特性。从误差角度来说，欠拟合时训练误差大，测试误差也大。</p>
<p><strong>过拟合</strong>就是模型过度学习了训练集所有特性，导致模型认为训练集中的某些特性也是潜在测试实例具有的一般性质。从误差角度来说，过拟合时训练误差小但测试误差却很大。</p>
<h3 id="1-8-损失函数-目标函数-与评价函数"><a href="#1-8-损失函数-目标函数-与评价函数" class="headerlink" title="1.8 损失函数(目标函数)与评价函数"></a>1.8 损失函数(目标函数)与评价函数</h3><p><strong>损失函数(loss)</strong>:通过最小化损失函数，使模型达到收敛状态，减少模型预测值的误差。</p>
<p><strong>评价函数(metric)</strong>:与损失函数类似，用于评价训练完的模型准确度，不参与模型训练。</p>
<div class="note note-secondary">
            <p>需要说明的是，相同的任务，采用不同的模型训练时可能采用不同的损失函数，不同的损失函数的数值用来评价不同模型的优劣没有意义，为此，在比较不同模型的优劣时，应该采用一致的评判标准，即采用相同的metric。</p>
          </div>
<h3 id="1-9-学习率"><a href="#1-9-学习率" class="headerlink" title="1.9 学习率"></a>1.9 学习率</h3><p> 在机器学习中，监督式学习通过定义一个模型，并根据训练集上的数据估计最优参数。梯度下降法是一个广泛被用来最小化模型误差的参数优化算法。梯度下降法通过多次迭代，并在每一步中最小化成本函数（cost 来估计模型的参数。学习率 (learning rate)，在迭代过程中会控制模型的学习进度。</p>
<p>在梯度下降法中，都是给定的统一的学习率，整个优化过程中都以确定的步长进行更新， 在迭代优化的前期中，学习率较大，则前进的步长就会较长，这时便能以较快的速度进行梯度下降，而在迭代优化的后期，逐步减小学习率的值，减小步长，这样将有助于算法的收敛，更容易接近最优解。故而如何对学习率的更新成为了研究者的关注点。 ​ 在模型优化中，常用到的几种学习率衰减方法有：分段常数衰减、多项式衰减、指数衰减、自然指数衰减、余弦衰减、线性余弦衰减、噪声线性余弦衰减</p>
<h4 id="1-9-1-分段常数衰减"><a href="#1-9-1-分段常数衰减" class="headerlink" title="1.9.1 分段常数衰减"></a>1.9.1 分段常数衰减</h4><p>分段常数衰减需要事先定义好的训练次数区间，在对应区间置不同的学习率的常数值，一般情况刚开始的学习率要大一些，之后要越来越小，要根据样本量的大小设置区间的间隔大小，样本量越大，区间间隔要小一点。下图即为分段常数衰减的学习率变化图，横坐标代表训练次数，纵坐标代表学习率。</p>
<p><img src="/imgs/deeplearning/ch3/learnrate1.png" srcset="/img/loading.gif" alt=""></p>
<h4 id="1-9-2-指数衰减"><a href="#1-9-2-指数衰减" class="headerlink" title="1.9.2 指数衰减"></a>1.9.2 指数衰减</h4><p>以指数衰减方式进行学习率的更新，学习率的大小和训练次数指数相关，其更新规则为：</p>
<script type="math/tex; mode=display">
decayed{\_}learning{\_}rate =learning{\_}rate*decay{\_}rate^{\frac{global{\_step}}{decay{\_}steps}}</script><p>这种衰减方式简单直接，收敛速度快，是最常用的学习率衰减方式，如下图所示，绿色的为学习率随训练次数的指数衰减方式，红色的即为分段常数衰减，它在一定的训练区间内保持学习率不变。</p>
<p><img src="/imgs/deeplearning/ch3/learnrate2.png" srcset="/img/loading.gif" alt=""></p>
<h4 id="1-9-3-自然指数衰减"><a href="#1-9-3-自然指数衰减" class="headerlink" title="1.9.3 自然指数衰减"></a>1.9.3 自然指数衰减</h4><p>它与指数衰减方式相似，不同的在于它的衰减底数是$e$，故而其收敛的速度更快，一般用于相对比较容易训练的网络，便于较快的收敛，其更新规则如下</p>
<script type="math/tex; mode=display">
decayed{\_}learning{\_}rate =learning{\_}rate*e^{\frac{-decay{\_rate}}{global{\_}step}}</script><p>下图为为分段常数衰减、指数衰减、自然指数衰减三种方式的对比图，红色的即为分段常数衰减图，阶梯型曲线。蓝色线为指数衰减图，绿色即为自然指数衰减图，很明可以看到自然指数衰减方式下的学习率衰减程度要大于一般指数衰减方式，有助于更快的收敛。</p>
<p><img src="/imgs/deeplearning/ch3/learnrate3.png" srcset="/img/loading.gif" alt=""></p>
<h4 id="1-9-4-多项式衰减"><a href="#1-9-4-多项式衰减" class="headerlink" title="1.9.4 多项式衰减"></a>1.9.4 多项式衰减</h4><p>应用多项式衰减的方式进行更新学习率，这里会给定初始学习率和最低学习率取值，然后将会按照给定的衰减方式将学习率从初始值衰减到最低值,其更新规则如下式所示。</p>
<script type="math/tex; mode=display">
global{\_}step=min(global{\_}step,decay{\_}steps)</script><script type="math/tex; mode=display">
decayed{\_}learning{\_}rate =(learning{\_}rate-end{\_}learning{\_}rate)* \left( 1-\frac{global{\_step}}{decay{\_}steps}\right)^{power} \\
 +end{\_}learning{\_}rate</script><p>需要注意的是，有两个机制，降到最低学习率后，到训练结束可以一直使用最低学习率进行更新，另一个是再次将学习率调高，使用 decay_steps 的倍数，取第一个大于 global_steps 的结果，如下式所示.它是用来防止神经网络在训练的后期由于学习率过小而导致的网络一直在某个局部最小值附近震荡，这样可以通过在后期增大学习率跳出局部极小值。</p>
<script type="math/tex; mode=display">
decay{\_}steps = decay{\_}steps*ceil \left( \frac{global{\_}step}{decay{\_}steps}\right)</script><p>如下图所示，红色线代表学习率降低至最低后，一直保持学习率不变进行更新，绿色线代表学习率衰减到最低后，又会再次循环往复的升高降低。</p>
<p><img src="/imgs/deeplearning/ch3/learnrate4.png" srcset="/img/loading.gif" alt=""></p>
<h4 id="1-9-5-余弦衰减"><a href="#1-9-5-余弦衰减" class="headerlink" title="1.9.5 余弦衰减"></a>1.9.5 余弦衰减</h4><p>余弦衰减就是采用余弦的相关方式进行学习率的衰减，衰减图和余弦函数相似。其更新机制如下式所示：</p>
<script type="math/tex; mode=display">
global{\_}step=min(global{\_}step,decay{\_}steps)</script><script type="math/tex; mode=display">
cosine{\_}decay=0.5*\left( 1+cos\left( \pi* \frac{global{\_}step}{decay{\_}steps}\right)\right)</script><script type="math/tex; mode=display">
decayed=(1-\alpha)*cosine{\_}decay+\alpha</script><script type="math/tex; mode=display">
decayed{\_}learning{\_}rate=learning{\_}rate*decayed</script><p>如下图所示，红色即为标准的余弦衰减曲线，学习率从初始值下降到最低学习率后保持不变。蓝色的线是线性余弦衰减方式曲线，它是学习率从初始学习率以线性的方式下降到最低学习率值。绿色噪声线性余弦衰减方式。</p>
<p><img src="/imgs/deeplearning/ch3/learnrate5.png" srcset="/img/loading.gif" alt=""></p>
<h2 id="二、卷积神经网络CNN"><a href="#二、卷积神经网络CNN" class="headerlink" title="二、卷积神经网络CNN"></a>二、卷积神经网络CNN</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">CNN层次结构</th>
<th style="text-align:center">输出尺寸</th>
<th style="text-align:left">作用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">输入层</td>
<td style="text-align:center">$W_1\times H_1\times 3$</td>
<td style="text-align:left">卷积网络的原始输入，可以是原始或预处理后的像素矩阵</td>
</tr>
<tr>
<td style="text-align:center">卷积层</td>
<td style="text-align:center">$W_1\times H_1\times K$</td>
<td style="text-align:left">参数共享、局部连接，利用平移不变性从全局特征图提取局部特征</td>
</tr>
<tr>
<td style="text-align:center">激活层</td>
<td style="text-align:center">$W_1\times H_1\times K$</td>
<td style="text-align:left">将卷积层的输出结果进行非线性映射</td>
</tr>
<tr>
<td style="text-align:center">池化层</td>
<td style="text-align:center">$W_2\times H_2\times K$</td>
<td style="text-align:left">进一步筛选特征，可以有效减少后续网络层次所需的参数量</td>
</tr>
<tr>
<td style="text-align:center">归一化层</td>
<td style="text-align:center">$W_2\times H_2\times K$</td>
<td style="text-align:left">对输入数据或特征进行归一化处理</td>
</tr>
<tr>
<td style="text-align:center">全连接层</td>
<td style="text-align:center">$(W_2 \cdot H_2 \cdot K)\times C$</td>
<td style="text-align:left">将多维特征展平为2维特征，通常低维度特征对应任务的学习目标（类别或回归值）</td>
</tr>
</tbody>
</table>
</div>
<div class="note note-secondary">
            <p>$W_1\times H_1\times 3$对应原始图像或经过预处理的像素值矩阵，3对应RGB图像的通道;$K$表示卷积层中卷积核（滤波器）的个数;$W_2\times H_2$ 为池化后特征图的尺度，在全局池化中尺度对应$1\times 1$;$(W_2 \cdot H_2 \cdot K)$是将多维特征压缩到1维之后的大小，$C$对应的则是图像类别个数。</p>
          </div>
<h3 id="2-1-输入层"><a href="#2-1-输入层" class="headerlink" title="2.1 输入层"></a>2.1 输入层</h3><p>输入层(Input Layer)通常是输入卷积神经网络的原始数据或经过预处理的数据，可以是图像识别领域中原始三维的多彩图像，也可以是音频识别领域中经过傅利叶变换的二维波形数据，甚至是自然语言处理中一维表示的句子向量。以图像分类任务为例，输入层输入的图像一般包含RGB三个通道，是一个由长宽分别为$H$和$W$组成的3维像素值矩阵$H\times W \times 3$，卷积网络会将输入层的数据传递到一系列卷积、池化等操作进行特征提取和转化，最终由全连接层对特征进行汇总和结果输出。根据计算能力、存储大小和模型结构的不同，卷积神经网络每次可以批量处理的图像个数不尽相同，若指定输入层接收到的图像个数为$N$，则输入层的输出数据为$N\times H\times W\times 3$。</p>
<h3 id="2-2-卷积层"><a href="#2-2-卷积层" class="headerlink" title="2.2 卷积层"></a>2.2 卷积层</h3><p>卷积层(Convolution Layer)通常用作对输入层输入数据进行特征提取，通过卷积核矩阵对原始数据中隐含关联性的一种抽象。卷积操作原理上其实是对两张像素矩阵进行点乘求和的数学操作，其中一个矩阵为输入的数据矩阵，另一个矩阵则为卷积核（滤波器或特征矩阵），求得的结果表示为原始图像中提取的特定局部特征。图5.1表示卷积操作过程中的不同填充策略，上半部分采用零填充，下半部分采用有效卷积（舍弃不能完整运算的边缘部分）。</p>
<p><img src="/imgs/deeplearning/ch5/convolution.png" srcset="/img/loading.gif" alt="conv-same"></p>
<h4 id="2-2-1-局部连接"><a href="#2-2-1-局部连接" class="headerlink" title="2.2.1 局部连接"></a>2.2.1 局部连接</h4><p>我们首先了解一个概念，感受野，即每个神经元仅与输入神经元相连接的一块区域。<br>在图像卷积操作中，神经元在空间维度上是局部连接，但在深度上是全连接。局部连接的思想，是受启发于生物学里的视觉系统结构，视觉皮层的神经元就是仅用局部接受信息。对于二维图像，局部像素关联性较强。这种局部连接保证了训练后的滤波器能够对局部特征有最强的响应，使神经网络可以提取数据的局部特征；<br>下图是一个很经典的图示，左边是全连接，右边是局部连接。</p>
<p><img src="/imgs/deeplearning/ch5/5.27.1.png" srcset="/img/loading.gif" alt="image"></p>
<p>对于一个1000 × 1000的输入图像而言，如果下一个隐藏层的神经元数目为10^6个，采用全连接则有1000 × 1000 × 10^6 = 10^12个权值参数，如此巨大的参数量几乎难以训练；而采用局部连接，隐藏层的每个神经元仅与图像中10 × 10的局部图像相连接，那么此时的权值参数数量为10 × 10 × 10^6 = 10^8，将直接减少4个数量级。</p>
<h4 id="2-2-2-权值共享"><a href="#2-2-2-权值共享" class="headerlink" title="2.2.2 权值共享"></a>2.2.2 权值共享</h4><p>权值共享，即计算同一深度的神经元时采用的卷积核参数是共享的。权值共享在一定程度上讲是有意义的，是由于在神经网络中，提取的底层边缘特征与其在图中的位置无关。但是在另一些场景中是无意的，如在人脸识别任务，我们期望在不同的位置学到不同的特征。</p>
<p>需要注意的是，权重只是对于同一深度切片的神经元是共享的。在卷积层中，通常采用多组卷积核提取不同的特征，即对应的是不同深度切片的特征，而不同深度切片的神经元权重是不共享。相反，偏置这一权值对于同一深度切片的所有神经元都是共享的。</p>
<p>权值共享带来的好处是大大降低了网络的训练难度。如下图，假设在局部连接中隐藏层的每一个神经元连接的是一个10 × 10的局部图像，因此有10 × 10个权值参数，将这10 × 10个权值参数共享给剩下的神经元，也就是说隐藏层中10^6个神经元的权值参数相同，那么此时不管隐藏层神经元的数目是多少，需要训练的参数就是这 10 × 10个权值参数（也就是卷积核的大小）。</p>
<p><img src="/imgs/deeplearning/ch5/5.27.2.png" srcset="/img/loading.gif" alt="image"></p>
<p>这里就体现了卷积神经网络的奇妙之处，使用少量的参数，却依然能有非常出色的性能。上述仅仅是提取图像一种特征的过程。如果要多提取出一些特征，可以增加多个卷积核，不同的卷积核能够得到图像不同尺度下的特征，称之为特征图（feature map）。</p>
<h4 id="2-2-3-卷积层参数"><a href="#2-2-3-卷积层参数" class="headerlink" title="2.2.3 卷积层参数"></a>2.2.3 卷积层参数</h4><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">参数名</th>
<th style="text-align:left">作用</th>
<th style="text-align:left">常见设置</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">卷积核大小 (Kernel Size)</td>
<td style="text-align:left">卷积核的大小定义了卷积的感受野</td>
<td style="text-align:left">在过去常设为5，如LeNet-5；现在多设为3，通过堆叠$3\times3$的卷积核来达到更大的感受域</td>
</tr>
<tr>
<td style="text-align:center">卷积核步长 (Stride)</td>
<td style="text-align:left">定义了卷积核在卷积过程中的步长</td>
<td style="text-align:left">常见设置为1，表示滑窗距离为1，可以覆盖所有相邻位置特征的组合；当设置为更大值时相当于对特征组合降采样</td>
</tr>
<tr>
<td style="text-align:center">填充方式 (Padding)</td>
<td style="text-align:left">在卷积核尺寸不能完美匹配输入的图像矩阵时需要进行一定的填充策略</td>
<td style="text-align:left">设置为’SAME’表示对不足卷积核大小的边界位置进行某种填充（通常零填充）以保证卷积输出维度与与输入维度一致；当设置为’VALID’时则对不足卷积尺寸的部分进行舍弃，输出维度就无法保证与输入维度一致</td>
</tr>
<tr>
<td style="text-align:center">输入通道数 (In Channels)</td>
<td style="text-align:left">指定卷积操作时卷积核的深度</td>
<td style="text-align:left">默认与输入的特征矩阵通道数（深度）一致；在某些压缩模型中会采用通道分离的卷积方式</td>
</tr>
<tr>
<td style="text-align:center">输出通道数 (Out Channels)</td>
<td style="text-align:left">指定卷积核的个数</td>
<td style="text-align:left">若设置为与输入通道数一样的大小，可以保持输入输出维度的一致性；若采用比输入通道数更小的值，则可以减少整体网络的参数量</td>
</tr>
</tbody>
</table>
</div>
<div class="note note-secondary">
            <p><strong>卷积操作维度变换公式:</strong></p><script type="math/tex; mode=display">O_d =\begin{cases} \lceil \frac{(I_d - k_{size})+ 1)}{s}\rceil ,& \text{padding=VALID}\\ \lceil \frac{I_d}{s}\rceil,&\text{padding=SAME} \end{cases}</script><p>其中，$I_d$为输入维度，$O_d$为输出维度，$k_{size}$为卷积核大小，$s$为步长</p>
          </div>
<h3 id="2-3-激活层"><a href="#2-3-激活层" class="headerlink" title="2.3 激活层"></a>2.3 激活层</h3><p>激活层(Activation Layer)负责对卷积层抽取的特征进行激活，由于卷积操作是由输入矩阵与卷积核矩阵进行相乘的线性变化关系，需要激活层对其进行非线性的映射。激活层主要由激活函数组成，即在卷积层输出结果的基础上嵌套一个非线性函数，让输出的特征图具有非线性关系。</p>
<div class="note note-secondary">
            <p><strong>使用非线性函数作为激活函数的理由:</strong></p><ul><li>假若网络中全部是线性部件，那么线性的组合还是线性，与单独一个线性分类器无异。这样就做不到用非线性来逼近任意函数。</li><li>使用非线性激活函数 ，以便使网络更加强大，增加它的能力，使它可以学习复杂的事物，复杂的表单数据，以及表示输入输出之间非线性的复杂的任意函数映射。使用非线性激活函数，能够从输入输出之间生成非线性映射。</li></ul>
          </div>
<h4 id="2-3-1-sigmoid-激活函数"><a href="#2-3-1-sigmoid-激活函数" class="headerlink" title="2.3.1 sigmoid 激活函数"></a>2.3.1 sigmoid 激活函数</h4><p>函数的定义为：$ f(x) = \frac{1}{1 + e^{-x}} $，其值域为 $ (0,1) $。</p>
<p>函数图像如下：</p>
<p><img src="/imgs/deeplearning/ch3/3-26.png" srcset="/img/loading.gif" alt=""></p>
<h4 id="2-3-2-tanh激活函数"><a href="#2-3-2-tanh激活函数" class="headerlink" title="2.3.2 tanh激活函数"></a>2.3.2 tanh激活函数</h4><p>函数的定义为：$ f(x) = tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} $，值域为 $ (-1,1) $。</p>
<p>函数图像如下：</p>
<p><img src="/imgs/deeplearning/ch3/3-27.png" srcset="/img/loading.gif" alt=""></p>
<h4 id="2-3-3-Relu激活函数"><a href="#2-3-3-Relu激活函数" class="headerlink" title="2.3.3 Relu激活函数"></a>2.3.3 Relu激活函数</h4><p>函数的定义为：$ f(x) = max(0, x) $  ，值域为 $ [0,+∞) $；</p>
<p>函数图像如下：</p>
<p><img src="/imgs/deeplearning/ch3/3-28.png" srcset="/img/loading.gif" alt=""></p>
<h4 id="2-3-4-Leak-Relu激活函数"><a href="#2-3-4-Leak-Relu激活函数" class="headerlink" title="2.3.4 Leak Relu激活函数"></a>2.3.4 Leak Relu激活函数</h4><p>函数定义为： $ f(x) =  \left\lbrace<br>   \begin{aligned}<br>   ax, \quad x<0 \\
   x, \quad x>0<br>   \end{aligned}<br>   \right. $，值域为 $ (-\infty,+\infty) $。 </p>
<p>图像如下（$ a = 0.5 $）：</p>
<p><img src="/imgs/deeplearning/ch3/3-29.png" srcset="/img/loading.gif" alt=""></p>
<h4 id="2-3-5-SoftPlus激活函数"><a href="#2-3-5-SoftPlus激活函数" class="headerlink" title="2.3.5 SoftPlus激活函数"></a>2.3.5 SoftPlus激活函数</h4><p>函数的定义为：$ f(x) = ln( 1 + e^x) $，值域为 $ (0,+\infty) $。</p>
<p>函数图像如下:</p>
<p><img src="/imgs/deeplearning/ch3/3-30.png" srcset="/img/loading.gif" alt=""></p>
<h4 id="2-3-6-softmax函数"><a href="#2-3-6-softmax函数" class="headerlink" title="2.3.6 softmax函数"></a>2.3.6 softmax函数</h4><p>函数定义为： $ \sigma(z)_j = \frac{e^{z_j}}{\sum_{k=1}^K e^{z_k}} $。</p>
<p>Softmax 多用于多分类神经网络输出。</p>
<h3 id="2-4-池化层-汇合层"><a href="#2-4-池化层-汇合层" class="headerlink" title="2.4 池化层(汇合层)"></a>2.4 池化层(汇合层)</h3><p>池化层又称为降采样层(Downsampling Layer)，作用是对感受域内的特征进行筛选，提取区域内最具代表性的特征，能够有效地降低输出特征尺度，进而减少模型所需要的参数量。按操作类型通常分为最大池化(Max Pooling)、平均池化(Average Pooling)和求和池化(Sum Pooling)，它们分别提取感受域内最大、平均与总和的特征值作为输出，最常用的是最大池化。</p>
<p><img src="/imgs/deeplearning/ch5/5.27.3.png" srcset="/img/loading.gif" alt="image"></p>
<h3 id="2-5-归一化层"><a href="#2-5-归一化层" class="headerlink" title="2.5 归一化层"></a>2.5 归一化层</h3><p>归一化层，目前主要有这几个方法:</p>
<ul>
<li><a href="https://arxiv.org/pdf/1502.03167.pdf" target="_blank" rel="noopener">Batch Normalization（2015年）</a></li>
<li><a href="https://arxiv.org/pdf/1607.06450v1.pdf" target="_blank" rel="noopener">Layer Normalization（2016年）</a></li>
<li><a href="https://arxiv.org/pdf/1607.08022.pdf" target="_blank" rel="noopener">Instance Normalization（2017年）</a></li>
<li><a href="https://arxiv.org/pdf/1803.08494.pdf" target="_blank" rel="noopener">Group Normalization（2018年）</a></li>
<li><a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">Local Response Normalization</a></li>
<li><a href="https://arxiv.org/pdf/1806.10779.pdf" target="_blank" rel="noopener">Switchable Normalization（2018年）</a></li>
</ul>
<p><img src="/imgs/deeplearning/norm.png" srcset="/img/loading.gif" alt=""></p>
<h4 id="2-5-1-Batch-Normalization"><a href="#2-5-1-Batch-Normalization" class="headerlink" title="2.5.1 Batch Normalization"></a>2.5.1 Batch Normalization</h4><p>首先，在进行训练之前，一般要对数据做归一化，使其分布一致，但是在深度神经网络训练过程中，通常以送入网络的每一个batch训练，这样每个batch具有不同的分布；此外，为了解决internal covarivate shift问题，这个问题定义是随着batch normalizaiton这篇论文提出的，在训练过程中，数据分布会发生变化，对下一层网络的学习带来困难。</p>
<p>所以batch normalization就是强行将数据拉回到均值为0，方差为1的正太分布上，这样不仅数据分布一致，而且避免发生梯度消失。</p>
<p>此外，internal corvariate shift和covariate shift是两回事，前者是网络内部，后者是针对输入数据，比如我们在训练数据前做归一化等预处理操作。</p>
<p>算法过程：</p>
<ul>
<li>沿着通道计算每个batch的均值$\mu$</li>
<li>沿着通道计算每个batch的方差$\sigma^2$</li>
<li>对$x$做归一化，$x’=\frac{\left(x-\mu\right)}{\sqrt{\left(\sigma^2+\varepsilon\right)}}$</li>
<li>加入缩放和平移变量γ和β ,归一化后的值，$y=\gamma x’+\beta$</li>
</ul>
<h4 id="2-5-2-Layer-Normalization"><a href="#2-5-2-Layer-Normalization" class="headerlink" title="2.5.2 Layer Normalization"></a>2.5.2 Layer Normalization</h4><p>与Batch Normalization不同，Layer Normalization是针对深度网络的某一层的所有神经元的输入按以下公式进行normalize操作。</p>
<script type="math/tex; mode=display">\mu^l=\frac{1}{H}\sum^H_{i=1}a_i^l</script><script type="math/tex; mode=display">\sigma^l=\sqrt{\frac{1}{H}\sum^H_{i=1}\left(a_i^l-\mu^l\right)^2}</script><p>Batch Normalization与Layer Normalization的区别在于：</p>
<p>Layer Normalization中同层神经元输入拥有相同的均值和方差，不同的输入样本有不同的均值和方差；<br>Batch Normalization中则针对不同神经元输入计算均值和方差，同一个batch中的输入拥有相同的均值和方差。</p>
<p>所以，Layer Normalization不依赖于batch的大小和输入sequence的深度，因此可以用于batchsize为1和RNN中对边长的输入sequence的normalize操作。</p>
<p>Layer Normalization用于RNN效果比较明显，但是在CNN上，不如Batch Normalization。</p>
<h4 id="2-5-3-Instance-Normalization"><a href="#2-5-3-Instance-Normalization" class="headerlink" title="2.5.3 Instance Normalization"></a>2.5.3 Instance Normalization</h4><p>Batch Normalization注重对每个batch进行归一化，保证数据分布一致，因为判别模型中结果取决于数据整体分布。</p>
<p>但是图像风格化中，生成结果主要依赖于某个图像实例，所以对整个batch归一化不适合图像风格化中，因而对HW做归一化。可以加速模型收敛，并且保持每个图像实例之间的独立。</p>
<h4 id="2-5-4-Group-Normalization"><a href="#2-5-4-Group-Normalization" class="headerlink" title="2.5.4 Group Normalization"></a>2.5.4 Group Normalization</h4><p>主要是针对Batch Normalization对小batchsize效果差，Group Normalization将channel方向分group，然后每个group内做归一化，算$\lfloor \frac{C}{G} \rfloor \times H \times W$的均值，这样与batchsize无关，不受其约束。</p>
<h4 id="2-5-5-Local-Response-Normalization"><a href="#2-5-5-Local-Response-Normalization" class="headerlink" title="2.5.5 Local Response Normalization"></a>2.5.5 Local Response Normalization</h4><p>局部响应归一化原理是仿造生物学上活跃的神经元对相邻神经元的抑制现象（侧抑制），然后根据论文有公式如下:</p>
<script type="math/tex; mode=display">b_{x,y}^i=\frac{a_{x,y}^i}{\left(k+\alpha\sum_{j=max\left(0,i-\frac{n}{2}\right)}^{min\left(N-1,i+\frac{n}{2}\right)}\left(a_{x,y}^j\right)\right)^\beta}</script><h4 id="2-5-6-Switchable-Normalization"><a href="#2-5-6-Switchable-Normalization" class="headerlink" title="2.5.6 Switchable Normalization"></a>2.5.6 Switchable Normalization</h4><ul>
<li>归一化虽然提高模型泛化能力，然而归一化层的操作是人工设计的。在实际应用中，解决不同的问题原则上需要设计不同的归一化操作，并没有一个通用的归一化方法能够解决所有应用问题；</li>
<li>一个深度神经网络往往包含几十个归一化层，通常这些归一化层都使用同样的归一化操作，因为手工为每一个归一化层设计操作需要进行大量的实验。</li>
</ul>
<p>因此作者提出自适配归一化方法——Switchable Normalization来解决上述问题。与强化学习不同，Switchable Normalization使用可微分学习，为一个深度网络中的每一个归一化层确定合适的归一化操作。</p>
<h3 id="2-6-全连接层"><a href="#2-6-全连接层" class="headerlink" title="2.6 全连接层"></a>2.6 全连接层</h3><p>全连接层(Full Connected Layer)负责对卷积神经网络学习提取到的特征进行汇总，将多维的特征输入映射为二维的特征输出，高维表示样本批次，低位常常对应任务目标。</p>
<h2 id="三、深度学习在计算机视觉中的应用"><a href="#三、深度学习在计算机视觉中的应用" class="headerlink" title="三、深度学习在计算机视觉中的应用"></a>三、深度学习在计算机视觉中的应用</h2><h3 id="3-1-图像识别"><a href="#3-1-图像识别" class="headerlink" title="3.1 图像识别"></a>3.1 图像识别</h3><p>计算机视觉中关于图像识别有四大类任务：</p>
<p><strong>分类-Classification</strong>：解决“是什么？”的问题，即给定一张图片或一段视频判断里面包含什么类别的目标。</p>
<p><strong>定位-Location</strong>：解决“在哪里？”的问题，即定位出这个目标的的位置。</p>
<p><strong>检测-Detection</strong>：解决“是什么？在哪里？”的问题，即定位出这个目标的的位置并且知道目标物是什么。</p>
<p><strong>分割-Segmentation</strong>：分为实例的分割（Instance-level）和场景分割（Scene-level），解决“每一个像素属于哪个目标物或场景”的问题。</p>
<p><img src="/imgs/deeplearning/ch8/8.1.1.png" srcset="/img/loading.gif" alt="图像识别四大类任务，图像来源于cs231n 2016课件Lecture 8"></p>
<h4 id="3-1-1-手写数字识别-MNIST"><a href="#3-1-1-手写数字识别-MNIST" class="headerlink" title="3.1.1 手写数字识别 MNIST"></a>3.1.1 手写数字识别 MNIST</h4><p><img src="/imgs/deeplearning/mnist.jpeg" srcset="/img/loading.gif" alt=""></p>
<h4 id="3-1-2-图像分割"><a href="#3-1-2-图像分割" class="headerlink" title="3.1.2 图像分割"></a>3.1.2 图像分割</h4><p>图像分割是预测图像中每一个像素所属的类别或者物体。基于深度学习的图像分割算法主要分为两类：</p>
<h5 id="3-1-2-1-语义分割"><a href="#3-1-2-1-语义分割" class="headerlink" title="3.1.2.1 语义分割"></a>3.1.2.1 语义分割</h5><p>为图像中的每个像素分配一个类别，如把画面中的所有物体都指出它们各自的类别。</p>
<div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/imgs/deeplearning/ch9/semantic-01.png" srcset="/img/loading.gif" alt=""></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="/imgs/deeplearning/seg1.jpg" srcset="/img/loading.gif" alt=""></div><div class="group-image-wrap"><img src="/imgs/deeplearning/seg2.jpg" srcset="/img/loading.gif" alt=""></div></div></div>
<h5 id="3-1-2-2-实例分割"><a href="#3-1-2-2-实例分割" class="headerlink" title="3.1.2.2 实例分割"></a>3.1.2.2 实例分割</h5><p>与语义分割不同，实例分割只对特定物体进行类别分配，这一点与目标检测有点相似，但目标检测输出的是边界框和类别，而实例分割输出的是掩膜（mask）和类别。</p>
<p><img src="/imgs/deeplearning/ch9/Instance-01.png" srcset="/img/loading.gif" alt=""></p>
<h4 id="3-1-3-目标检测"><a href="#3-1-3-目标检测" class="headerlink" title="3.1.3 目标检测"></a>3.1.3 目标检测</h4><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/imgs/deeplearning/det1.jpg" srcset="/img/loading.gif" alt=""></div><div class="group-image-wrap"><img src="/imgs/deeplearning/det3.png" srcset="/img/loading.gif" alt=""></div></div></div>
<h4 id="3-1-4-人脸识别"><a href="#3-1-4-人脸识别" class="headerlink" title="3.1.4 人脸识别"></a>3.1.4 人脸识别</h4><h5 id="3-1-4-1-FaceNet"><a href="#3-1-4-1-FaceNet" class="headerlink" title="3.1.4.1 FaceNet"></a>3.1.4.1 FaceNet</h5><p><img src="/imgs/deeplearning/facenet.png" srcset="/img/loading.gif" alt=""></p>
<h5 id="3-1-4-2-OpenFace"><a href="#3-1-4-2-OpenFace" class="headerlink" title="3.1.4.2 OpenFace"></a>3.1.4.2 OpenFace</h5><p><img src="/imgs/deeplearning/openface.png" srcset="/img/loading.gif" alt=""></p>
<h5 id="3-1-4-3-VRN"><a href="#3-1-4-3-VRN" class="headerlink" title="3.1.4.3 VRN"></a>3.1.4.3 VRN</h5><p><img src="/imgs/deeplearning/vrn.png" srcset="/img/loading.gif" alt=""></p>
<h3 id="3-2-立体匹配-Stereo-Match"><a href="#3-2-立体匹配-Stereo-Match" class="headerlink" title="3.2 立体匹配 Stereo Match"></a>3.2 立体匹配 Stereo Match</h3><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/imgs/deeplearning/stereo/Adirondack_left.png" srcset="/img/loading.gif" alt=""></div><div class="group-image-wrap"><img src="/imgs/deeplearning/stereo/Adirondack.png" srcset="/img/loading.gif" alt=""></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="/imgs/deeplearning/stereo/ArtL_left.png" srcset="/img/loading.gif" alt=""></div><div class="group-image-wrap"><img src="/imgs/deeplearning/stereo/ArtL.png" srcset="/img/loading.gif" alt=""></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="/imgs/deeplearning/stereo/Motorcycle_left.png" srcset="/img/loading.gif" alt=""></div><div class="group-image-wrap"><img src="/imgs/deeplearning/stereo/Motorcycle.png" srcset="/img/loading.gif" alt=""></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="/imgs/deeplearning/stereo/Recycle_left.png" srcset="/img/loading.gif" alt=""></div><div class="group-image-wrap"><img src="/imgs/deeplearning/stereo/Recycle.png" srcset="/img/loading.gif" alt=""></div></div></div>
<h3 id="3-3-图像复原-Image-Restoration"><a href="#3-3-图像复原-Image-Restoration" class="headerlink" title="3.3 图像复原 Image Restoration"></a>3.3 图像复原 Image Restoration</h3><h4 id="3-3-1-图像去噪-Denoising"><a href="#3-3-1-图像去噪-Denoising" class="headerlink" title="3.3.1 图像去噪 Denoising"></a>3.3.1 图像去噪 Denoising</h4><p><img src="/imgs/deeplearning/denoising.png" srcset="/img/loading.gif" alt=""></p>
<h4 id="3-3-2-图像超分-Super-resolution"><a href="#3-3-2-图像超分-Super-resolution" class="headerlink" title="3.3.2 图像超分 Super resolution"></a>3.3.2 图像超分 Super resolution</h4><p><img src="/imgs/deeplearning/super-resolution.png" srcset="/img/loading.gif" alt=""></p>
<h4 id="3-3-3-图像修复-Inpainting"><a href="#3-3-3-图像修复-Inpainting" class="headerlink" title="3.3.3 图像修复 Inpainting"></a>3.3.3 图像修复 Inpainting</h4><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/imgs/deeplearning/640.jpeg" srcset="/img/loading.gif" alt=""></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="/imgs/deeplearning/inpainting.jpeg" srcset="/img/loading.gif" alt=""></div></div></div>
<h3 id="3-4-三维重建-Reconstruction"><a href="#3-4-三维重建-Reconstruction" class="headerlink" title="3.4 三维重建 Reconstruction"></a>3.4 三维重建 Reconstruction</h3><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/imgs/deeplearning/rmvsnet1.png" srcset="/img/loading.gif" alt=""></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="/imgs/deeplearning/rmvsnet2.png" srcset="/img/loading.gif" alt=""></div></div></div>
<h3 id="3-5-风格转移-Style-Transfer"><a href="#3-5-风格转移-Style-Transfer" class="headerlink" title="3.5 风格转移 Style Transfer"></a>3.5 风格转移 Style Transfer</h3><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/imgs/deeplearning/styletransfer1.png" srcset="/img/loading.gif" alt=""></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="/imgs/deeplearning/styletransfer2.png" srcset="/img/loading.gif" alt=""></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="/imgs/deeplearning/styletransfer3.png" srcset="/img/loading.gif" alt=""></div></div></div>
<h2 id="四、深度学习工具"><a href="#四、深度学习工具" class="headerlink" title="四、深度学习工具"></a>四、深度学习工具</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">开发框架</th>
<th style="text-align:center">开发语言</th>
<th style="text-align:center">支持平台</th>
<th style="text-align:center">自动求导</th>
<th style="text-align:center">预训练模型</th>
<th style="text-align:center">CNN开发</th>
<th style="text-align:center">RNN开发</th>
<th style="text-align:center">单机多卡并行</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Caffe</td>
<td style="text-align:center">C++</td>
<td style="text-align:center">Linux,Mac OS X,Windows</td>
<td style="text-align:center">不支持</td>
<td style="text-align:center">提供</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">支持</td>
</tr>
<tr>
<td style="text-align:center">Keras</td>
<td style="text-align:center">Python</td>
<td style="text-align:center">Linux,Mac OS X,Windows</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">提供</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">不支持</td>
</tr>
<tr>
<td style="text-align:center">MXNet</td>
<td style="text-align:center">C++</td>
<td style="text-align:center">Linux,Mac OS X,Windows</td>
<td style="text-align:center">不支持</td>
<td style="text-align:center">提供</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">支持</td>
</tr>
<tr>
<td style="text-align:center">TensorFlow</td>
<td style="text-align:center">C++,Python</td>
<td style="text-align:center">Linux,Mac OS X,Windows</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">提供</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">支持</td>
</tr>
<tr>
<td style="text-align:center">Theano</td>
<td style="text-align:center">Python</td>
<td style="text-align:center">Cross-platform</td>
<td style="text-align:center">不支持</td>
<td style="text-align:center">不提供</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">不支持</td>
</tr>
<tr>
<td style="text-align:center">Pytorch</td>
<td style="text-align:center">Python</td>
<td style="text-align:center">Linux,Mac OS X</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">提供</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">支持</td>
<td style="text-align:center">支持</td>
</tr>
</tbody>
</table>
</div>
<h3 id="4-1-常用框架的特点"><a href="#4-1-常用框架的特点" class="headerlink" title="4.1 常用框架的特点"></a>4.1 常用框架的特点</h3><h4 id="4-1-1-Caffe"><a href="#4-1-1-Caffe" class="headerlink" title="4.1.1 Caffe"></a>4.1.1 Caffe</h4><p>Caffe是一个广为人知、广泛应用侧重计算机视觉方面的深度学习库，由加州大学伯克利分校BVLC组开发，总结来说， Caffe 有以下优缺点：</p>
<ul>
<li>✓ 适合前馈网络和图像处理；</li>
<li>✓ 适合微调已有的网络模型；</li>
<li>✓ 训练已有网络模型无需编写任何代码；</li>
<li>✓ 提供方便的Python和Matlab接口；</li>
<li>✗ 可单机多卡，但不支持多机多卡；</li>
<li>✗ 需要用C++/CUDA编写新的GPU层；</li>
<li>✗ 不适合循环网络；</li>
<li>✗ 用于大型网络（如，GoogLeNet\ResNet）时过于繁琐；</li>
<li>✗ 扩展性稍差，代码有些不够精简；</li>
<li>✗ 不提供商业支持；</li>
<li>✗ 框架更新缓慢，可能之后不再更新。</li>
</ul>
<h4 id="4-1-2-Keras"><a href="#4-1-2-Keras" class="headerlink" title="4.1.2 Keras"></a>4.1.2 Keras</h4><p>Keras由谷歌软件工程师Francois Chollet开发，是一个基于Theano和TensorFlow的深度学习库，具有一个受Torch启发、较为直观的API。其优缺点如下：</p>
<ul>
<li>✓ 受Torch启发的直观API;</li>
<li>✓ 可使用Theano、TensorFlow和Deeplearning4j后端；</li>
<li>✓ 支持自动求导；</li>
<li>✓ 框架更新速度快</li>
</ul>
<h4 id="4-1-3-TensorFlow"><a href="#4-1-3-TensorFlow" class="headerlink" title="4.1.3 TensorFlow"></a>4.1.3 TensorFlow</h4><p>TensorFlow是Google负责开发的用Python API编写，通过C/C++引擎加速的深度学习框架，是目前受关注最多的深度学习框架。它使用数据流图集成深度学习中最常见的单元，并支持许多最新的CNN网络结构以及不同设置的RNN。其优缺点为：</p>
<ul>
<li>✓ 具备不局限于深度学习的多种用途，还有支持强化学习和其他算法的工具；</li>
<li>✓ 跨平台运行能力强；</li>
<li>✓ 支持自动求导；</li>
<li>✗ 运行明显比其他框架慢；</li>
<li>✗ 不提供商业支持。</li>
</ul>
<h4 id="4-1-4-Torch"><a href="#4-1-4-Torch" class="headerlink" title="4.1.4 Torch"></a>4.1.4 Torch</h4><p>Torch是用Lua编写带API的科学计算框架，支持机器学习算法。Facebook和Twitter等大型科技公司使用Torch的某些版本，由内部团队专门负责定制自己的深度学习平台。其优缺点如下：</p>
<ul>
<li>✓ 大量模块化组件，容易组合；</li>
<li>✓ 易编写新的网络层；</li>
<li>✓ 支持丰富的预训练模型；</li>
<li>✓ Pytorch为Torch提供了更便利的接口；</li>
<li>✗ 使用Lua语言需要学习成本；</li>
<li>✗ 文档质量参差不齐；</li>
<li>✗ 一般需要自己编写训练代码（即插即用相对较少）。</li>
</ul>
<h3 id="4-2-Docker"><a href="#4-2-Docker" class="headerlink" title="4.2 Docker"></a>4.2 Docker</h3><h4 id="4-2-1-虚拟机与容器"><a href="#4-2-1-虚拟机与容器" class="headerlink" title="4.2.1 虚拟机与容器"></a>4.2.1 虚拟机与容器</h4><p>虚拟机（virtual machine）可以在一种操作系统里面运行另一种操作系统，比如在 Windows 系统里面运行 Linux 系统。应用程序对此毫无感知，因为虚拟机看上去跟真实系统一模一样，而对于底层系统来说，虚拟机就是一个普通文件，不需要了就删掉，对其他部分毫无影响。</p>
<p>但是，虚拟机有几个缺点:</p>
<ul>
<li><strong>资源占用多。</strong>虚拟机会独占一部分内存和硬盘空间。它运行的时候，其他程序就不能使用这些资源了。哪怕虚拟机里面的应用程序，真正使用的内存只有 1MB，虚拟机依然需要几百 MB 的内存才能运行。</li>
<li><strong>冗余步骤多。</strong>虚拟机是完整的操作系统，一些系统级别的操作步骤，往往无法跳过，比如用户登录。</li>
<li><strong>启动慢。</strong>启动操作系统需要多久，启动虚拟机就需要多久。可能要等几分钟，应用程序才能真正运行。</li>
</ul>
<p>由于虚拟机存在这些缺点，Linux 发展出了另一种虚拟化技术：Linux 容器（Linux Containers，缩写为 LXC）。</p>
<p>Linux 容器不是模拟一个完整的操作系统，而是对进程进行隔离。或者说，在正常进程的外面套了一个保护层。对于容器里面的进程来说，它接触到的各种资源都是虚拟的，从而实现与底层系统的隔离。</p>
<p>由于容器是进程级别的，相比虚拟机有很多优势。</p>
<ul>
<li><strong>启动快。</strong>容器里面的应用，直接就是底层系统的一个进程，而不是虚拟机内部的进程。所以，启动容器相当于启动本机的一个进程，而不是启动一个操作系统，速度就快很多。</li>
<li><strong>资源占用少。</strong>容器只占用需要的资源，不占用那些没有用到的资源；虚拟机由于是完整的操作系统，不可避免要占用所有资源。另外，多个容器可以共享资源，虚拟机都是独享资源。</li>
<li><strong>体积小。</strong>容器只要包含用到的组件即可，而虚拟机是整个操作系统的打包，所以容器文件比虚拟机文件要小很多。</li>
</ul>
<p>总之，容器有点像轻量级的虚拟机，能够提供虚拟化的环境，但是成本开销小得多。</p>
<h4 id="4-2-2-Docker及其使用"><a href="#4-2-2-Docker及其使用" class="headerlink" title="4.2.2 Docker及其使用"></a>4.2.2 Docker及其使用</h4><p>Docker 将应用程序与该程序的依赖，打包在一个文件(<strong>镜像</strong>)里面。运行这个文件，就会生成一个虚拟<strong>容器</strong>。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。</p>
<h5 id="4-2-2-1-docker的用途"><a href="#4-2-2-1-docker的用途" class="headerlink" title="4.2.2.1 docker的用途"></a>4.2.2.1 docker的用途</h5><p>Docker 的主要用途，目前有三大类。</p>
<ul>
<li><strong>提供一次性的环境。</strong>比如，本地测试他人的软件、持续集成的时候提供单元测试和构建的环境。</li>
<li><strong>提供弹性的云服务。</strong>因为 Docker 容器可以随开随关，很适合动态扩容和缩容。</li>
<li><strong>组建微服务架构。</strong>通过多个容器，一台机器可以跑多个服务，因此在本机就可以模拟出微服务架构。</li>
</ul>
<h5 id="4-2-2-2-docker使用"><a href="#4-2-2-2-docker使用" class="headerlink" title="4.2.2.2 docker使用"></a>4.2.2.2 docker使用</h5><p><strong>查看镜像(Image)</strong><br><pre><code class="hljs plain">docker images</code></pre></p>
<p><strong>创建并启动容器(container)</strong><br><pre><code class="hljs plain">docker run -it -v VOLUME --name NAME IMAGE</code></pre></p>
<p><strong>停止容器</strong><br><pre><code class="hljs plain">docker stop CONTAINER</code></pre></p>
<p><strong>启动容器</strong><br><pre><code class="hljs plain">docker start CONTAINER</code></pre></p>
<p><strong>进入容器</strong><br><pre><code class="hljs plain">docker attach CONTAINER</code></pre><br><strong>删除容器</strong><br><pre><code class="hljs plain">docker rm CONTAINER</code></pre></p>
<p><strong>删除镜像</strong><br><pre><code class="hljs plain">docker rmi IMAGE</code></pre></p>

            </article>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" target="_blank" rel="nofollow noopener noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                  </div>
                </div>
              
            </div>

            
              <!-- Comments -->
              <div class="comments" id="comments">
                
                
  <div id="vcomments"></div>
  <script defer src="https://cdn.staticfile.org/valine/1.4.14/Valine.min.js" ></script>

  <script type="text/javascript">
    var oldLoadVa = window.onload;
    window.onload = function () {
      oldLoadVa && oldLoadVa();

      new Valine({
        el: "#vcomments",
        app_id: "KKrnC7r3XXGKwp1TgYmCOTIW-gzGzoHsz",
        app_key: "gxzi3YsuzYzUxxC8VbrJtekm",
        placeholder: "说点什么",
        path: window.location.pathname,
        avatar: "retro",
        meta: ["nick","mail","link"],
        pageSize: "10",
        lang: "zh-CN",
        highlight: false,
        recordIP: false,
        serverURLs: "",
      });
    };
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://valine.js.org" target="_blank" rel="nofollow noopener noopener">comments
      powered by Valine.</a></noscript>


              </div>
            
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    

    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/main.js" ></script>


  <script  src="/js/lazyload.js" ></script>



  
  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '.post-content',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>





  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>






<!-- Plugins -->



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "深度学习入门&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.staticfile.org/mathjax/3.0.5/es5/tex-svg.js" ></script>

  














</body>
</html>
